{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d9c5505",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [28]</a>'.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d87c22-4387-4aa1-9ad5-d7c515adefd2",
   "metadata": {
    "papermill": {
     "duration": 0.137157,
     "end_time": "2022-02-07T09:56:42.990427",
     "exception": false,
     "start_time": "2022-02-07T09:56:42.853270",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# HOUSE PRICES TRAINER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c329355-4ccf-4ef3-88e1-b85c76e3f51b",
   "metadata": {
    "papermill": {
     "duration": 0.343865,
     "end_time": "2022-02-07T09:56:43.434708",
     "exception": false,
     "start_time": "2022-02-07T09:56:43.090843",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.6\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eab36b8-9bf8-43de-9fc6-456c74b6a0bd",
   "metadata": {
    "papermill": {
     "duration": 0.115908,
     "end_time": "2022-02-07T09:56:43.675630",
     "exception": false,
     "start_time": "2022-02-07T09:56:43.559722",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## DATA AND GLOBAL PARAMETERS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f58c2b-ed1f-4287-a6aa-4d83d0f0b263",
   "metadata": {
    "papermill": {
     "duration": 0.114935,
     "end_time": "2022-02-07T09:56:43.898809",
     "exception": false,
     "start_time": "2022-02-07T09:56:43.783874",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bdd4665b-d318-44ad-90e0-d2bb500f9c25",
   "metadata": {
    "papermill": {
     "duration": 0.680925,
     "end_time": "2022-02-07T09:56:44.685941",
     "exception": false,
     "start_time": "2022-02-07T09:56:44.005016",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LIRBARIES ------\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "# Misc\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "# Combinatorics\n",
    "from itertools import product\n",
    "from pickle import dump\n",
    "\n",
    "# Matrices\n",
    "import numpy as np\n",
    "\n",
    "# DF\n",
    "import pandas as pd\n",
    "\n",
    "# Boosting machine\n",
    "import pkg_resources\n",
    "pkg_resources.require(\"xgboost == 1.5.2\")\n",
    "import xgboost as xgb\n",
    "\n",
    "from IPython.display import Markdown as md\n",
    "from IPython.display import display as printmd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.metrics import (\n",
    "    make_scorer,\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    "    mean_squared_log_error,\n",
    ")\n",
    "from sklearn.model_selection import GridSearchCV, KFold, train_test_split\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.svm import SVC, SVR\n",
    "\n",
    "# SKLEARN ---\n",
    "# * metrics ---\n",
    "\n",
    "# * Preprocess ---\n",
    "\n",
    "# * Imputation\n",
    "\n",
    "# * CV ---\n",
    "\n",
    "# Regression\n",
    "\n",
    "\n",
    "# utils \n",
    "base_path = \"/home/jovyan/work/CM_ML/TP5/Maturite_dentaire\"  # laptop : /home/jovyan/work/CM_ML/TP3_TP4 other tower: /home/jovyan/work/TP3_TP4\n",
    "os.chdir(base_path)\n",
    "sys.path.append(base_path)\n",
    "from utils.utils import rmsle_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae74c8f9-0436-4bd1-b8b4-9b11b9eb18b6",
   "metadata": {
    "papermill": {
     "duration": 0.122451,
     "end_time": "2022-02-07T09:56:44.913899",
     "exception": false,
     "start_time": "2022-02-07T09:56:44.791448",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting time and time used for files 07-02-2022_10:03:12\n"
     ]
    }
   ],
   "source": [
    "# START TIME ------\n",
    "s = datetime.now()\n",
    "# time as str\n",
    "init_time = s.strftime(\"%d-%m-%Y_%H:%M:%S\")\n",
    "print(f\"Starting time and time used for files {init_time}\")\n",
    "pd.set_option(\"display.float_format\", lambda x: \"%.5f\" % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cde833b-9037-4544-b051-8f8776264fbd",
   "metadata": {
    "papermill": {
     "duration": 0.107019,
     "end_time": "2022-02-07T09:56:45.123126",
     "exception": false,
     "start_time": "2022-02-07T09:56:45.016107",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Helper functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3eb0f29-3e7c-4ca0-b863-532b57157a59",
   "metadata": {
    "papermill": {
     "duration": 0.118573,
     "end_time": "2022-02-07T09:56:45.346144",
     "exception": false,
     "start_time": "2022-02-07T09:56:45.227571",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# FROM DATA TO MODEL DATA -----\n",
    "def preprocess_data_as_model(data, dependent, categorical):\n",
    "    # * Divide X,y ---\n",
    "    data_subset = data.drop(dependent, axis=1)\n",
    "    y = data[dependent].values\n",
    "\n",
    "    # handle categorical variables ---\n",
    "    cols_beginning = data_subset.columns.values\n",
    "\n",
    "    all_cols = cols_beginning\n",
    "    numeric_cols = data_subset.select_dtypes([\"number\"]).columns\n",
    "    numeric_cols_index = np.in1d(all_cols, numeric_cols)\n",
    "\n",
    "    categorical_cols = data_subset.select_dtypes([\"object\"]).columns\n",
    "    categorical_cols_index = np.in1d(all_cols, categorical_cols)\n",
    "\n",
    "    # Transformations ---\n",
    "    transformations = []\n",
    "\n",
    "    if categorical:\n",
    "        pass  # todo\n",
    "    else:\n",
    "        # Training cols ---\n",
    "        data_subset = data_subset.select_dtypes([\"number\"])  # drop categorical\n",
    "        all_cols = cols_beginning[numeric_cols_index]  # only numerical cols ....\n",
    "        numeric_cols_index = (\n",
    "            data_subset.columns.values != None\n",
    "        )  # apply transformation to all columns\n",
    "    return (\n",
    "        data_subset,\n",
    "        y,\n",
    "        all_cols,\n",
    "        numeric_cols,\n",
    "        numeric_cols_index,\n",
    "        categorical_cols,\n",
    "        categorical_cols_index,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a33c6740-4817-4146-b107-44a966451313",
   "metadata": {
    "papermill": {
     "duration": 0.115611,
     "end_time": "2022-02-07T09:56:45.568000",
     "exception": false,
     "start_time": "2022-02-07T09:56:45.452389",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MODEL TRAINERS ------\n",
    "\n",
    "\n",
    "def train_mlp(data=None, best_params=None):\n",
    "    # * Init xgb instance ---\n",
    "    mlp = MLPRegressor(max_iter=3000, random_state=123, early_stopping=True)\n",
    "    # * Set best params, normally found by a previous Grid search ---\n",
    "    if best_params:\n",
    "        print(f\"Setting best parameters: {best_params}\")\n",
    "        mlp.set_params(**best_params)\n",
    "    if data:\n",
    "        # * Fit mlp: ((x_train,y_train)) ---\n",
    "        mlp.fit(X=data[0], y=data[1])\n",
    "    return mlp\n",
    "\n",
    "\n",
    "def train_svr(data=None, best_params=None):\n",
    "    # * Init xgb instance ---\n",
    "    svr = SVR()\n",
    "    # * Set best params, normally found by a previous Grid search ---\n",
    "    if best_params:\n",
    "        print(f\"Setting best parameters: {best_params}\")\n",
    "        svr.set_params(**best_params)\n",
    "    if data:\n",
    "        # * Fit svr: ((x_train,y_train)) ---\n",
    "        svr.fit(X=data[0], y=data[1])\n",
    "    return svr\n",
    "\n",
    "\n",
    "def train_rf(data=None, best_params=None):\n",
    "    # * Init xgb instance ---\n",
    "    rf = RandomForestRegressor()\n",
    "\n",
    "    # * Set best params, normally found by a previous Grid search ---\n",
    "    if best_params:\n",
    "        print(f\"Setting best parameters: {best_params}\")\n",
    "        rf.set_params(**best_params)\n",
    "    if data:\n",
    "        # * Fit rf: ((x_train,y_train)) ---\n",
    "        rf.fit(X=data[0], y=data[1])\n",
    "    return rf\n",
    "\n",
    "\n",
    "def train_xgb(params, data=None, best_params=None):\n",
    "    # * Init xgb instance ---\n",
    "    boost = xgb.XGBRegressor(**params)\n",
    "\n",
    "    # * Set best params, normally found by a previous Grid search ---\n",
    "    if best_params:\n",
    "        print(f\"Setting best parameters: {best_params}\")\n",
    "        boost.set_params(**best_params)\n",
    "\n",
    "    # * Fit booster: ((x_train,y_train), (x_test,y_test)) ---\n",
    "    if data:\n",
    "        boost.fit(\n",
    "            X=data[0][0],\n",
    "            y=data[0][1],\n",
    "            eval_set=data,  # Validation set for early stopping (validates on test -- last data tuple)\n",
    "            early_stopping_rounds=10,\n",
    "            verbose=0,\n",
    "            eval_metric=[\"mae\", \"rmse\", \"rmsle\"],\n",
    "        )\n",
    "    return boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c03037fe-8168-449f-815f-80a0a0595d2c",
   "metadata": {
    "papermill": {
     "duration": 0.11961,
     "end_time": "2022-02-07T09:56:45.795995",
     "exception": false,
     "start_time": "2022-02-07T09:56:45.676385",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_mlp_classification(data=None, best_params=None):\n",
    "    # * Init xgb instance ---\n",
    "    mlp = MLPClassifier(max_iter=3000, random_state=123, early_stopping=True)\n",
    "    # * Set best params, normally found by a previous Grid search ---\n",
    "    if best_params:\n",
    "        print(f\"Setting best parameters: {best_params}\")\n",
    "        mlp.set_params(**best_params)\n",
    "    if data:\n",
    "        # * Fit mlp: ((x_train,y_train)) ---\n",
    "        mlp.fit(X=data[0], y=data[1])\n",
    "    return mlp\n",
    "\n",
    "\n",
    "def train_svr_classification(data=None, best_params=None):\n",
    "    # * Init xgb instance ---\n",
    "    svr = SVC()\n",
    "    # * Set best params, normally found by a previous Grid search ---\n",
    "    if best_params:\n",
    "        print(f\"Setting best parameters: {best_params}\")\n",
    "        svr.set_params(**best_params)\n",
    "    if data:\n",
    "        # * Fit svr: ((x_train,y_train)) ---\n",
    "        svr.fit(X=data[0], y=data[1])\n",
    "    return svr\n",
    "\n",
    "\n",
    "def train_rf_classification(data=None, best_params=None):\n",
    "    # * Init xgb instance ---\n",
    "    rf = RandomForestClassifier()\n",
    "\n",
    "    # * Set best params, normally found by a previous Grid search ---\n",
    "    if best_params:\n",
    "        print(f\"Setting best parameters: {best_params}\")\n",
    "        rf.set_params(**best_params)\n",
    "    if data:\n",
    "        # * Fit rf: ((x_train,y_train)) ---\n",
    "        rf.fit(X=data[0], y=data[1])\n",
    "    return rf\n",
    "\n",
    "\n",
    "def train_xgb_classification(params, data=None, best_params=None):\n",
    "    # * Init xgb instance ---\n",
    "    boost = xgb.XGBClassifier(**params)\n",
    "\n",
    "    # * Set best params, normally found by a previous Grid search ---\n",
    "    if best_params:\n",
    "        print(f\"Setting best parameters: {best_params}\")\n",
    "        boost.set_params(**best_params)\n",
    "\n",
    "    # * Fit booster: ((x_train,y_train), (x_test,y_test)) ---\n",
    "    if data:\n",
    "        boost.fit(\n",
    "            X=data[0][0],\n",
    "            y=data[0][1],\n",
    "            eval_set=data,  # Validation set for early stopping (validates on test -- last data tuple)\n",
    "            early_stopping_rounds=10,\n",
    "            verbose=0,\n",
    "            eval_metric=[\"mae\", \"rmse\", \"rmsle\"],\n",
    "        )\n",
    "    return boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8997e70-1f93-4f22-8b3b-37667252e789",
   "metadata": {
    "papermill": {
     "duration": 0.119547,
     "end_time": "2022-02-07T09:56:46.020077",
     "exception": false,
     "start_time": "2022-02-07T09:56:45.900530",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MODEL SAVERS ------\n",
    "\n",
    "\n",
    "def save_model(\n",
    "    model,\n",
    "    model_name,\n",
    "    dataset,\n",
    "    kind,\n",
    "    objective,\n",
    "    toScale,\n",
    "    best_score,\n",
    "    init_time,\n",
    "    columns_used,\n",
    "    Preprocess,\n",
    "    preprocessing_path,\n",
    "    categorical,\n",
    "    scores,\n",
    ") -> str:\n",
    "    print(\"\\n\")\n",
    "    print(\"--- Saving model ---\")\n",
    "    model_path = f\"model_dump/{model_name}_{dataset}_{kind}_{objective}_{toScale}_{np.round(best_score,5)}_{init_time}.pkl\"\n",
    "\n",
    "    dump(\n",
    "        {  # options\n",
    "            \"scaled\": toScale,\n",
    "            \"categorical\": categorical,\n",
    "            # processing and model\n",
    "            \"columns_used\": columns_used,\n",
    "            \"preprocess\": Preprocess,\n",
    "            \"model\": model,\n",
    "            \"preprocessing_path\": preprocessing_path,\n",
    "            # outcome\n",
    "            \"scores\": scores,\n",
    "        },\n",
    "        open(model_path, \"wb\"),\n",
    "    )\n",
    "\n",
    "    print(f\"--- {model_name} model saved to {model_path}---\")\n",
    "    return model_path\n",
    "\n",
    "\n",
    "def save_grid(\n",
    "    model_path,\n",
    "    model_name,\n",
    "    dataset,\n",
    "    init_time,\n",
    "    preprocessing_path,\n",
    "    toScale,\n",
    "    categorical,\n",
    "    search,\n",
    "):\n",
    "\n",
    "    res = pd.DataFrame(search.cv_results_)\n",
    "\n",
    "    # * Save estimator ---\n",
    "    res[\"model_path\"] = model_path\n",
    "\n",
    "    # * Did we scale ?\n",
    "    if preprocessing_path:\n",
    "        res[\"preprocessing_path\"] = preprocessing_path\n",
    "    else:\n",
    "        res[\"preprocessing_path\"] = \"no preprocess\"\n",
    "\n",
    "    res[\"categorical\"] = categorical\n",
    "\n",
    "    # * To csv ---\n",
    "    grid_name = f\"grid_search/Grid_{model_name}_{dataset}_{init_time}.csv\"\n",
    "    res.to_csv(grid_name)\n",
    "    print(f\"--- Grid search results saved to {grid_name}---\")\n",
    "\n",
    "\n",
    "def score_model(model, data):\n",
    "    \"\"\"\n",
    "    data = ((xtrain, ytrain), (x_val, y_val), (x_test, y_test))\n",
    "    \"\"\"\n",
    "    splits = [\"train\", \"val\", \"test\"]\n",
    "    scores = {}\n",
    "    for i, split in enumerate(splits):\n",
    "        metrics = {}\n",
    "        metrics[\"rmsle\"] = rmsle(model, data[i][0], data[i][1])\n",
    "        metrics[\"rmse\"] = mean_squared_error(model.predict(data[i][0]), data[i][1])\n",
    "        metrics[\"mae\"] = mean_absolute_error(model.predict(data[i][0]), data[i][1])\n",
    "        scores[split] = metrics\n",
    "    return scores\n",
    "\n",
    "\n",
    "def scores_to_df(scores, verbose=True):\n",
    "    scores_df = pd.DataFrame(scores)\n",
    "    scores_df[\"difference\"] = scores_df[\"train\"] - scores_df[\"val\"]\n",
    "    if verbose:\n",
    "        print(\"---- BEST SCORES ---\")\n",
    "        print(scores_df)\n",
    "    return scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b4b7ec-a38c-4d21-aa0c-0612e45a5c82",
   "metadata": {
    "papermill": {
     "duration": 0.116979,
     "end_time": "2022-02-07T09:56:46.239273",
     "exception": false,
     "start_time": "2022-02-07T09:56:46.122294",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### FITTERS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fd0f2d3-111f-427a-aa53-3331fc52e078",
   "metadata": {
    "papermill": {
     "duration": 0.11912,
     "end_time": "2022-02-07T09:56:46.460516",
     "exception": false,
     "start_time": "2022-02-07T09:56:46.341396",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_results(model, data):\n",
    "    # PRINT BEST RESULTS ------\n",
    "    scores = score_model(model, data)\n",
    "    scores_df = scores_to_df(scores)\n",
    "\n",
    "    best_params = model.get_params()\n",
    "    printmd(md(f\"Paramètres du modèle: {best_params}\"))\n",
    "    return scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3725046-58c1-4ca2-90c9-1be796b02bf9",
   "metadata": {
    "papermill": {
     "duration": 0.117052,
     "end_time": "2022-02-07T09:56:46.682912",
     "exception": false,
     "start_time": "2022-02-07T09:56:46.565860",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fit_baseline_model(trainer, data, pass_val=False, params=False, **kwargs):\n",
    "    # --- --- --- BASELINE --- --- ---\n",
    "    kind = \"baseline\"\n",
    "\n",
    "    # * Fit if requested ---\n",
    "    if pass_val and params:\n",
    "        model = trainer(params, data, best_params=None)\n",
    "    else:\n",
    "        model = trainer((data[0][0], data[0][1]), best_params=None)\n",
    "\n",
    "    # Best rmsle ---\n",
    "    best_score = rmsle(estimator=model, X=data[1][0], y_true=data[1][1])\n",
    "\n",
    "    return (model, kind, best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7193dc1-5e9c-4890-a2fb-550048092ca8",
   "metadata": {
    "papermill": {
     "duration": 0.165546,
     "end_time": "2022-02-07T09:56:46.953211",
     "exception": false,
     "start_time": "2022-02-07T09:56:46.787665",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fit_grid_model(\n",
    "    trainer,\n",
    "    data,\n",
    "    grid_params,\n",
    "    grid_search_kwargs,\n",
    "    pass_val=False,\n",
    "    params=False,\n",
    "    verbose=True,\n",
    "):\n",
    "    # --- --- --- BASELINE --- --- ---\n",
    "    kind = \"grid\"\n",
    "\n",
    "    if params:\n",
    "        # * Init instance ---\n",
    "        model = trainer(params=params)\n",
    "    else:\n",
    "        model = trainer()\n",
    "\n",
    "    # * GridSearchCV ---\n",
    "    search = GridSearchCV(model, param_grid=grid_params, **grid_search_kwargs)\n",
    "\n",
    "    # * Fit if requested ---\n",
    "    if pass_val:\n",
    "        search.fit(\n",
    "            data[0][0],\n",
    "            data[0][1],\n",
    "            eval_set=[data[1]],  # Validation set for early stopping\n",
    "            early_stopping_rounds=15,\n",
    "            verbose=0,\n",
    "        )\n",
    "    else:\n",
    "        search.fit(data[0][0], data[0][1])\n",
    "\n",
    "    # PRINT BEST RESULTS ------\n",
    "    if verbose:\n",
    "        best_score = search.best_score_\n",
    "        printmd(\n",
    "            md(\n",
    "                f\"Le meilleur score obtenu par notre grid search (à savoir, le score est le RMSLE): {best_score}\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "        best_params = search.best_params_\n",
    "        printmd(md(f\"Le meilleurs paramètres: {best_params}\"))\n",
    "\n",
    "    return search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99a13e88-d427-4cd6-b689-3d9eedbcc3b2",
   "metadata": {
    "papermill": {
     "duration": 0.119598,
     "end_time": "2022-02-07T09:56:47.182825",
     "exception": false,
     "start_time": "2022-02-07T09:56:47.063227",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def refit_with_params(trainer, best_params, data, pass_val=False):\n",
    "    # * Fit if requested ---\n",
    "    if pass_val and params:\n",
    "        model = trainer(params, data, best_params=best_params)\n",
    "    else:\n",
    "        model = trainer((data[0][0], data[0][1]), best_params=best_params)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0014db5-9140-43bf-824b-3023a0aa4f80",
   "metadata": {
    "papermill": {
     "duration": 0.121767,
     "end_time": "2022-02-07T09:56:47.408675",
     "exception": false,
     "start_time": "2022-02-07T09:56:47.286908",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def refit_with_selection(\n",
    "    trainer,\n",
    "    data,\n",
    "    model_with_importances,\n",
    "    all_cols,\n",
    "    grid_params,\n",
    "    grid_search_kwargs,\n",
    "    pass_val,\n",
    "    params,\n",
    "    best_params,\n",
    "    th=0.001,\n",
    "    verbose=False,\n",
    "):\n",
    "    # which features ---\n",
    "    subset = model_with_importances.feature_importances_ > th\n",
    "    important_cols = all_cols[subset].tolist()\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"IMPORTANT COLUMNS KEPT FOR RETRAINING {important_cols}\")\n",
    "\n",
    "    data_th = [(data[0][0][:, subset], data[0][1]), (data[1][0][:, subset], data[1][1])]\n",
    "    search = fit_grid_model(\n",
    "        trainer, data_th, grid_params, grid_search_kwargs, pass_val, params, verbose\n",
    "    )\n",
    "\n",
    "    model = refit_with_params(\n",
    "        trainer, search.best_params_, data=data_th, pass_val=pass_val\n",
    "    )\n",
    "\n",
    "    best_score = search.best_score_\n",
    "    return model, important_cols, subset, best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebb1be4-f292-49ad-87e6-6860926cc874",
   "metadata": {
    "papermill": {
     "duration": 0.109558,
     "end_time": "2022-02-07T09:56:47.622548",
     "exception": false,
     "start_time": "2022-02-07T09:56:47.512990",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Data Paths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b54d143-6978-426a-bc89-6b54855a3959",
   "metadata": {
    "papermill": {
     "duration": 0.112394,
     "end_time": "2022-02-07T09:56:47.842303",
     "exception": false,
     "start_time": "2022-02-07T09:56:47.729909",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- --- --- FOLDERS AND FILES --- --- ---\n",
    "\n",
    "# * Wine dataset paths ---\n",
    "data_path = \"data/ordinalEncoder_imputed_knn/\"\n",
    "knnImputed_path= os.path.join(base_path, data_path, \"knn_imputed.csv\")\n",
    "\n",
    "# init scaler\n",
    "scaler_name = None\n",
    "Preprocess = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89367d19-0135-47d5-95cc-c3421fc8c756",
   "metadata": {
    "papermill": {
     "duration": 0.114736,
     "end_time": "2022-02-07T09:56:48.072564",
     "exception": false,
     "start_time": "2022-02-07T09:56:47.957828",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# --- --- --- MODEL FITTING PARAMETERS --- --- ---\n",
    "\n",
    "# FIT OR LOAD MODEL ------\n",
    "toFitXGB = True\n",
    "toFitRF = True\n",
    "toFitSVM = True\n",
    "toFitMLP = True\n",
    "\n",
    "# * Fitting options ---\n",
    "toScale = True\n",
    "\n",
    "# *Handle categorical vars\n",
    "categorical = True\n",
    "\n",
    "# DEFAULT STORAGE PARAMETERS ------\n",
    "to_rm_storage = True\n",
    "### DATA PARAMETERS ---\n",
    "training_data_path = None\n",
    "dataset = None\n",
    "dependent = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0bc1aff8",
   "metadata": {
    "papermill": {
     "duration": 0.114533,
     "end_time": "2022-02-07T09:56:48.296266",
     "exception": false,
     "start_time": "2022-02-07T09:56:48.181733",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "training_data_path = \"knnImputed_path\"\n",
    "dataset = \"knnImputed\"\n",
    "dependent = \"PAT_AGE\"\n",
    "categorical = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08150bd-62a2-4d80-b7ca-a8fc033670ad",
   "metadata": {
    "papermill": {
     "duration": 0.116244,
     "end_time": "2022-02-07T09:56:48.516884",
     "exception": false,
     "start_time": "2022-02-07T09:56:48.400640",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Folders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0fb1da5e-e78e-49b4-817d-baff9ff2516d",
   "metadata": {
    "papermill": {
     "duration": 0.118067,
     "end_time": "2022-02-07T09:56:48.749198",
     "exception": false,
     "start_time": "2022-02-07T09:56:48.631131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Removing previous saved models, grids and scalers ---\n",
      "CPU times: user 3.52 ms, sys: 3.75 ms, total: 7.27 ms\n",
      "Wall time: 4.97 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# FOLDERS TO STORE ------\n",
    "paths_to_create = [\n",
    "    os.path.join(base_path, \"scale_dump\"),\n",
    "    os.path.join(base_path, \"model_dump\"),\n",
    "    os.path.join(base_path, \"grid_search\"),\n",
    "]\n",
    "\n",
    "# REMOVE PREVIOUS STORAGE IF NEEDED ------\n",
    "if to_rm_storage:\n",
    "    print(\"--- Removing previous saved models, grids and scalers ---\")\n",
    "    for folder in paths_to_create:\n",
    "        shutil.rmtree(folder, ignore_errors=True)\n",
    "\n",
    "# (RE)CREATE STORAGE FOLDERS ------\n",
    "for folder in paths_to_create:\n",
    "    os.makedirs(folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7a80e7-c61c-4a9e-8b64-61e04f23457b",
   "metadata": {
    "papermill": {
     "duration": 0.118293,
     "end_time": "2022-02-07T09:56:48.972822",
     "exception": false,
     "start_time": "2022-02-07T09:56:48.854529",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## MODEL PARAMETERS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4888bc90-804c-4e00-b3e8-466dc5deff71",
   "metadata": {
    "papermill": {
     "duration": 0.11389,
     "end_time": "2022-02-07T09:56:49.190048",
     "exception": false,
     "start_time": "2022-02-07T09:56:49.076158",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### MODEL PARAMETERS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1206c0-cd17-41cd-b76e-339f1698abe2",
   "metadata": {
    "papermill": {
     "duration": 0.113202,
     "end_time": "2022-02-07T09:56:49.408601",
     "exception": false,
     "start_time": "2022-02-07T09:56:49.295399",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "265249ef-80a6-4525-9773-1595ddf85459",
   "metadata": {
    "papermill": {
     "duration": 0.116553,
     "end_time": "2022-02-07T09:56:49.635393",
     "exception": false,
     "start_time": "2022-02-07T09:56:49.518840",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPUS DETECTED : 8\n",
      "CPUS TO USE : 6\n"
     ]
    }
   ],
   "source": [
    "# Multiprocessing ---\n",
    "cpus = multiprocessing.cpu_count()\n",
    "cpu_ratio = 0.8\n",
    "cpus_to_use = int(cpus * cpu_ratio)\n",
    "print(f\"CPUS DETECTED : {cpus}\")\n",
    "print(f\"CPUS TO USE : {cpus_to_use}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c93f4c-c461-4387-abfb-9062fe687a3b",
   "metadata": {
    "papermill": {
     "duration": 0.111966,
     "end_time": "2022-02-07T09:56:49.859299",
     "exception": false,
     "start_time": "2022-02-07T09:56:49.747333",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### CV PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d36cee3-2623-4300-8b83-9520ff00fb99",
   "metadata": {
    "papermill": {
     "duration": 0.116433,
     "end_time": "2022-02-07T09:56:50.084496",
     "exception": false,
     "start_time": "2022-02-07T09:56:49.968063",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- --- --- CV PARAMS --- --- ---\n",
    "folds = 3\n",
    "rstate = 123\n",
    "\n",
    "# * K Fold ---\n",
    "skf = KFold(n_splits=folds, shuffle=True, random_state=rstate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "77fa33b4-9378-4a0c-9b00-b5277aa25d4c",
   "metadata": {
    "papermill": {
     "duration": 0.116432,
     "end_time": "2022-02-07T09:56:50.314446",
     "exception": false,
     "start_time": "2022-02-07T09:56:50.198014",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- --- --- XGB HYPER PARAMS --- --- ---\n",
    "# * Grid for xgb ---\n",
    "xgb_params = {\n",
    "    \"min_child_weight\": [1, 5, 10],\n",
    "    \"gamma\": [0.001, 0.02, 0.04, 0.08, 0.1, 0.5],\n",
    "    \"subsample\": [0.6, 0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.6, 0.8, 1.0],\n",
    "    \"max_depth\": [1, 2, 4, 5],\n",
    "    \"lambda\": [0, 0.01, 0.02, 0.5, 1],  # no much pbs of overfting\n",
    "}\n",
    "objective = \"reg:squaredlogerror\"  # metric RMSLE\n",
    "objective = \"reg:squarederror\"  # RMSLE STUCKED ...\n",
    "metric = \"mae\"\n",
    "rmsle = rmsle_scorer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41b98e16-0c9a-4fae-9eab-2eb1281c43ba",
   "metadata": {
    "papermill": {
     "duration": 0.136782,
     "end_time": "2022-02-07T09:56:50.562293",
     "exception": false,
     "start_time": "2022-02-07T09:56:50.425511",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Original Number of combinations : 5474\n",
      "RF Number of correct combinations : 912\n"
     ]
    }
   ],
   "source": [
    "# --- --- --- RANDOM FOREST HYPER PARAMS --- --- ---\n",
    "max_depth_val = 18\n",
    "max_depth = np.arange(1, max_depth_val, 1)\n",
    "max_leaf_nodes = np.arange(\n",
    "    2, max_depth_val * max_depth_val, 1\n",
    ")  # si on ajoute un max_depth x il faut au plus accepter x*x feuilles...\n",
    "\n",
    "params_combinations = list(product(max_depth, max_leaf_nodes))\n",
    "print(\"RF Original Number of combinations : %s\" % len(params_combinations))\n",
    "\n",
    "# REMOVE ILOGIC COMBINATIONS cf.TP2 ------\n",
    "correct_params = []\n",
    "incorrect_params = []\n",
    "for depth, leaves in params_combinations:\n",
    "    max_feuilles = depth * depth\n",
    "    if leaves > max_feuilles or leaves < np.round(0.5 * max_feuilles):  # critères\n",
    "        incorrect_params.append((depth, leaves))\n",
    "    else:\n",
    "        correct_params.append((depth, leaves))\n",
    "\n",
    "rf_params = []\n",
    "for depth, leaves in correct_params:\n",
    "    grille = {\n",
    "        \"max_depth\": [depth],  # wrap in one list element\n",
    "        \"max_leaf_nodes\": [leaves],\n",
    "    }\n",
    "    rf_params.append(grille)\n",
    "\n",
    "print(\"RF Number of correct combinations : %s\" % len(correct_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee02bc68-6f18-4bca-8eee-62c2a2debd92",
   "metadata": {
    "papermill": {
     "duration": 0.114473,
     "end_time": "2022-02-07T09:56:50.786749",
     "exception": false,
     "start_time": "2022-02-07T09:56:50.672276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- --- --- SVM HYPER PARAMS --- --- ---\n",
    "\n",
    "# possibilities ---\n",
    "Cs = np.linspace(0.5, 40, 7)\n",
    "KERNELS = [\"linear\", \"poly\", \"rbf\", \"sigmoid\"]\n",
    "# grid ---\n",
    "svm_params = {\"C\": Cs, \"kernel\": KERNELS}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd1466d7-326b-453a-8e2d-54d7e32545ac",
   "metadata": {
    "papermill": {
     "duration": 0.117264,
     "end_time": "2022-02-07T09:56:51.012036",
     "exception": false,
     "start_time": "2022-02-07T09:56:50.894772",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- --- --- MLP HYPER PARAMS --- --- ---\n",
    "\n",
    "mlp_params = {\n",
    "    \"hidden_layer_sizes\": [(50, 50, 50), (50, 100, 50), (100,)],\n",
    "    \"activation\": [\"tanh\", \"relu\"],\n",
    "    \"solver\": [\"sgd\", \"adam\"],\n",
    "    \"alpha\": [0.0001, 0.05],\n",
    "    \"learning_rate\": [\"constant\", \"adaptive\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc8463b-ca71-45ac-a2e7-3df3ae727757",
   "metadata": {
    "papermill": {
     "duration": 0.1214,
     "end_time": "2022-02-07T09:56:51.238088",
     "exception": false,
     "start_time": "2022-02-07T09:56:51.116688",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## IMPORT DATA "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f915346b-977c-433d-8ab2-a5a234fd3555",
   "metadata": {
    "papermill": {
     "duration": 0.116044,
     "end_time": "2022-02-07T09:56:51.458485",
     "exception": false,
     "start_time": "2022-02-07T09:56:51.342441",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### House "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9efbacad-e9ef-4dbd-97e9-a357ee536079",
   "metadata": {
    "papermill": {
     "duration": 1.070467,
     "end_time": "2022-02-07T09:56:52.635419",
     "exception": false,
     "start_time": "2022-02-07T09:56:51.564952",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Column Transformation. Scaling:True , OneHotEncoder : False  ---\n",
      "CPU times: user 39.1 ms, sys: 57.4 ms, total: 96.5 ms\n",
      "Wall time: 1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# --- --- --- DATA --- --- ---\n",
    "# * Load data ---\n",
    "data = pd.read_csv(eval(training_data_path), sep=\",\")\n",
    "\n",
    "(\n",
    "    data_subset,\n",
    "    y,\n",
    "    all_cols,\n",
    "    numeric_cols,\n",
    "    numeric_cols_index,\n",
    "    categorical_cols,\n",
    "    categorical_cols_index,\n",
    ") = preprocess_data_as_model(data, dependent, categorical)\n",
    "cols_beginning = data_subset.columns.values\n",
    "\n",
    "# DEFINE TRANSFORMATION BASED ON OPTIONS ------\n",
    "# Transformations ---\n",
    "transformations = []\n",
    "if categorical:\n",
    "    # One hot encoder ---\n",
    "    encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "    transformer = (\"cat_cols\", encoder, categorical_cols_index)  # on cat cols\n",
    "    transformations.append(transformer)\n",
    "\n",
    "else:\n",
    "    # Training cols ---\n",
    "    data_subset = data_subset.select_dtypes([\"number\"])  # drop categorical\n",
    "    all_cols = cols_beginning[numeric_cols_index]  # only numerical cols ....\n",
    "    numeric_cols_index = (\n",
    "        data_subset.columns.values != None\n",
    "    )  # apply transformation to all columns\n",
    "\n",
    "\n",
    "# * Optional Scaling ---\n",
    "if toScale:\n",
    "    # unit variance scaler ---\n",
    "    scaler = StandardScaler()\n",
    "    transformer = (\"num_cols\", scaler, numeric_cols_index)  # on num cols\n",
    "    transformations.append(transformer)\n",
    "\n",
    "# * TRAIN VAL TEST SPLIT ---\n",
    "# train test\n",
    "X_train, XHold_test, y_train, yHold_test = train_test_split(\n",
    "    data_subset.values, y, test_size=0.15, random_state=rstate\n",
    ")\n",
    "# train validation\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(\n",
    "    X_train, y_train, test_size=0.15, random_state=rstate\n",
    ")\n",
    "\n",
    "#\n",
    "\n",
    "if toScale or categorical:\n",
    "    print(\n",
    "        f\"--- Column Transformation. Scaling:{toScale} , OneHotEncoder : {categorical}  ---\"\n",
    "    )\n",
    "    Preprocess = ColumnTransformer(\n",
    "        transformations, n_jobs=cpus_to_use, remainder=\"passthrough\"\n",
    "    )\n",
    "    # fit ---\n",
    "    X_train = Preprocess.fit_transform(X_train)\n",
    "    X_validation = Preprocess.transform(X_validation)\n",
    "    XHold_test = Preprocess.transform(XHold_test)\n",
    "\n",
    "    # get names ---\n",
    "    all_cols = Preprocess.get_feature_names_out()\n",
    "\n",
    "    # dump to reuse\n",
    "    scaler_name = f\"scale_dump/ColumnTransformer_{dataset}_{init_time}.pkl\"\n",
    "    dump(Preprocess, open(scaler_name, \"wb\"))\n",
    "\n",
    "# TRAIN VAL TEST SPLIT ------\n",
    "data_splits = [\n",
    "    (X_train, y_train),\n",
    "    (X_validation, y_validation),\n",
    "    (XHold_test, yHold_test),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be860d2a-1571-4c8f-b5a9-2bd5e978e33e",
   "metadata": {
    "papermill": {
     "duration": 0.118415,
     "end_time": "2022-02-07T09:56:52.864013",
     "exception": false,
     "start_time": "2022-02-07T09:56:52.745598",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "grid_search_kwargs = dict(\n",
    "    scoring=rmsle, n_jobs=cpus_to_use, refit=True, cv=skf, verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed03a8c9-7c6d-4674-a2bd-4be6f7317e27",
   "metadata": {
    "papermill": {
     "duration": 0.113968,
     "end_time": "2022-02-07T09:56:53.099939",
     "exception": false,
     "start_time": "2022-02-07T09:56:52.985971",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## XGBOOST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b31cdf5c-e1e8-4709-98c5-7d96bd7f8a17",
   "metadata": {
    "papermill": {
     "duration": 0.11899,
     "end_time": "2022-02-07T09:56:53.330092",
     "exception": false,
     "start_time": "2022-02-07T09:56:53.211102",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "saver_params = dict(\n",
    "    dataset=dataset,\n",
    "    model_name=\"xgb\",\n",
    "    objective=objective,\n",
    "    toScale=toScale,\n",
    "    init_time=init_time,\n",
    "    columns_used=all_cols,\n",
    "    Preprocess=Preprocess,\n",
    "    preprocessing_path=scaler_name,\n",
    "    categorical=categorical,\n",
    ")\n",
    "\n",
    "saver_grid_params = {}\n",
    "for i in [\n",
    "    \"model_name\",\n",
    "    \"dataset\",\n",
    "    \"init_time\",\n",
    "    \"preprocessing_path\",\n",
    "    \"toScale\",\n",
    "    \"categorical\",\n",
    "]:\n",
    "    saver_grid_params[i] = saver_params.get(i)\n",
    "\n",
    "params = {\n",
    "    \"objective\": objective,\n",
    "    \"learning_rate\": 0.02,\n",
    "    \"n_estimators\": 700,\n",
    "    \"n_jobs\": 1,  # if not defaults to -1...\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4faa5f84-83b9-4c90-892c-f10422123b66",
   "metadata": {
    "papermill": {
     "duration": 0.115801,
     "end_time": "2022-02-07T09:56:53.559889",
     "exception": false,
     "start_time": "2022-02-07T09:56:53.444088",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### BASIC MODEL (NO HPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "501cb85c-62ca-4c35-a8f1-a931c38caa35",
   "metadata": {
    "papermill": {
     "duration": 0.219538,
     "end_time": "2022-02-07T09:56:53.888613",
     "exception": false,
     "start_time": "2022-02-07T09:56:53.669075",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'xgboost' has no attribute 'XGBRegressor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_5972/975313453.py\u001b[0m in \u001b[0;36mfit_baseline_model\u001b[0;34m(trainer, data, pass_val, params, **kwargs)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# * Fit if requested ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpass_val\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_5972/1344291947.py\u001b[0m in \u001b[0;36mtrain_xgb\u001b[0;34m(params, data, best_params)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_xgb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;31m# * Init xgb instance ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mboost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;31m# * Set best params, normally found by a previous Grid search ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'xgboost' has no attribute 'XGBRegressor'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# --- --- --- XGBOOST --- --- ---\n",
    "if toFitXGB:\n",
    "    model, kind, best_score = fit_baseline_model(\n",
    "        train_xgb,\n",
    "        data=[(X_train, y_train), (X_validation, y_validation)],\n",
    "        pass_val=True,\n",
    "        params=params,\n",
    "    )\n",
    "\n",
    "    scores_df = get_results(model, data_splits)\n",
    "    # SAVE RESULTS ------\n",
    "    save_model(\n",
    "        model=model, kind=kind, best_score=best_score, scores=scores_df, **saver_params\n",
    "    )\n",
    "    # boost.get_booster().feature_names= important_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729e4e95-b6e4-4fd5-89e0-f7d05ca2450f",
   "metadata": {
    "papermill": {
     "duration": 0.111669,
     "end_time": "2022-02-07T09:56:54.114275",
     "exception": false,
     "start_time": "2022-02-07T09:56:54.002606",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### GRID SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "37755148-2fa9-464f-a20d-6c209325bef5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-07T09:56:54.345390Z",
     "iopub.status.busy": "2022-02-07T09:56:54.344773Z",
     "iopub.status.idle": "2022-02-07T09:56:54.356950Z",
     "shell.execute_reply": "2022-02-07T09:56:54.356479Z"
    },
    "papermill": {
     "duration": 0.12886,
     "end_time": "2022-02-07T09:56:54.357069",
     "exception": false,
     "start_time": "2022-02-07T09:56:54.228209",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'xgboost' has no attribute 'XGBRegressor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_5862/222452214.py\u001b[0m in \u001b[0;36mfit_grid_model\u001b[0;34m(trainer, data, grid_params, grid_search_kwargs, pass_val, params, verbose)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# * Init instance ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_5862/1344291947.py\u001b[0m in \u001b[0;36mtrain_xgb\u001b[0;34m(params, data, best_params)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_xgb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;31m# * Init xgb instance ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mboost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;31m# * Set best params, normally found by a previous Grid search ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'xgboost' has no attribute 'XGBRegressor'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# --- --- --- XGBOOST GRID SEARCH --- --- ---\n",
    "if toFitXGB:\n",
    "    kind = \"grid\"\n",
    "\n",
    "    search = fit_grid_model(\n",
    "        train_xgb,\n",
    "        data=[(X_train, y_train), (X_validation, y_validation)],\n",
    "        grid_params=xgb_params,\n",
    "        grid_search_kwargs=grid_search_kwargs,\n",
    "        pass_val=True,\n",
    "        params=params,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    # REFIT TO GET TRAINING ERROR AT EACH STEP ------\n",
    "\n",
    "    model = refit_with_params(\n",
    "        train_xgb,\n",
    "        search.best_estimator_.get_xgb_params(),\n",
    "        data=[(X_train, y_train), (X_validation, y_validation)],\n",
    "        pass_val=True,\n",
    "    )\n",
    "    # Score model ---\n",
    "    scores_df = get_results(model, data_splits)\n",
    "    best_score = search.best_score_\n",
    "    # Save model ---\n",
    "    model_path = save_model(\n",
    "        model=model, kind=kind, best_score=best_score, scores=scores_df, **saver_params\n",
    "    )\n",
    "    # Save grid search results ---\n",
    "    save_grid(model_path=model_path, search=search, **saver_grid_params)\n",
    "    # boost.get_booster().feature_names= important_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c0b82c-7cb2-4898-baab-f916b1766e6d",
   "metadata": {
    "papermill": {
     "duration": 0.112867,
     "end_time": "2022-02-07T09:56:54.583235",
     "exception": false,
     "start_time": "2022-02-07T09:56:54.470368",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Refit on feature selection "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4836310",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c9486b96-a180-47ca-8e50-54bfae922f10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-07T09:56:54.815846Z",
     "iopub.status.busy": "2022-02-07T09:56:54.815167Z",
     "iopub.status.idle": "2022-02-07T09:56:54.822133Z",
     "shell.execute_reply": "2022-02-07T09:56:54.821425Z"
    },
    "papermill": {
     "duration": 0.127211,
     "end_time": "2022-02-07T09:56:54.822339",
     "exception": true,
     "start_time": "2022-02-07T09:56:54.695128",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5862/2301171834.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mtrain_xgb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_validation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mmodel_with_importances\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mall_cols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_cols\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mgrid_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgb_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "if toFitXGB:\n",
    "    model, important_cols, subset, best_score = refit_with_selection(\n",
    "        train_xgb,\n",
    "        [(X_train, y_train), (X_validation, y_validation)],\n",
    "        model_with_importances=model,\n",
    "        all_cols=all_cols,\n",
    "        grid_params=xgb_params,\n",
    "        grid_search_kwargs=grid_search_kwargs,\n",
    "        pass_val=True,\n",
    "        params=params,\n",
    "        best_params=search.best_estimator_.get_xgb_params(),\n",
    "        th=0.001,\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    model.get_booster().feature_names = important_cols\n",
    "\n",
    "    data_splits_th = [\n",
    "        (data_splits[0][0][:, subset], data_splits[0][1]),\n",
    "        (data_splits[1][0][:, subset], data_splits[1][1]),\n",
    "        (data_splits[2][0][:, subset], data_splits[2][1]),\n",
    "    ]\n",
    "\n",
    "    scores_df = get_results(model, data_splits_th)\n",
    "    # Save model ---\n",
    "    kind = \"refit\"\n",
    "    model_path = save_model(\n",
    "        model=model, kind=kind, best_score=best_score, scores=scores_df, **saver_params\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92dc3d7-6238-447e-81e5-44d0863987f7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## RF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4c47ec-7d1d-40be-ba9d-00db2bf58dc2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# * Split for learning ---\n",
    "# train test\n",
    "if toFitRF or toFitMLP or toFitSVM:\n",
    "\n",
    "    X_train, XHold_test, y_train, yHold_test = train_test_split(\n",
    "        data_subset.values, y, test_size=0.15, random_state=rstate\n",
    "    )\n",
    "    # train validation\n",
    "    X_train, X_validation, y_train, y_validation = train_test_split(\n",
    "        X_train, y_train, test_size=0.15, random_state=rstate\n",
    "    )\n",
    "\n",
    "    knnI = KNNImputer()\n",
    "    #\n",
    "    if toScale or categorical:\n",
    "        print(\n",
    "            f\"--- Column Transformation. Scaling:{toScale} , OneHotEncoder : {categorical}, Imputer : knnImputer  ---\"\n",
    "        )\n",
    "        Preprocess = ColumnTransformer(\n",
    "            transformations, n_jobs=cpus_to_use, remainder=\"passthrough\"\n",
    "        )\n",
    "\n",
    "        Preprocess = Pipeline([(\"col_trans\", Preprocess), (\"imputer\", knnI)])\n",
    "    else:\n",
    "        Preprocess = Pipeline([(\"imputer\", knnI)])\n",
    "\n",
    "    # fit ---\n",
    "    Preprocess.fit(X_train)\n",
    "    X_train = Preprocess.transform(X_train)\n",
    "    X_validation = Preprocess.transform(X_validation)\n",
    "    XHold_test = Preprocess.transform(XHold_test)\n",
    "\n",
    "    # get names ---\n",
    "    if toScale or categorical:\n",
    "\n",
    "        all_cols = Preprocess[0].get_feature_names_out()\n",
    "\n",
    "    # dump to reuse\n",
    "    preprocessing_name = f\"scale_dump/ColumnTransformer__rf_{init_time}.pkl\"\n",
    "    dump(Preprocess, open(preprocessing_name, \"wb\"))\n",
    "\n",
    "# TRAIN VAL TEST SPLIT ------\n",
    "data_splits = [\n",
    "    (X_train, y_train),\n",
    "    (X_validation, y_validation),\n",
    "    (XHold_test, yHold_test),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a48298-3ca5-4168-bc0a-d9fceda01119",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### BASIC MODEL (NO HPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa7e26e-bda0-4988-b044-ff6a03618153",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "saver_params = dict(\n",
    "    dataset=dataset,\n",
    "    model_name=\"rf\",\n",
    "    objective=\"squared_error\",\n",
    "    toScale=toScale,\n",
    "    init_time=init_time,\n",
    "    columns_used=all_cols,\n",
    "    Preprocess=Preprocess,\n",
    "    preprocessing_path=scaler_name,\n",
    "    categorical=categorical,\n",
    ")\n",
    "# --- --- --- BASELINE RF --- --- ---\n",
    "if toFitRF:\n",
    "    model, kind, best_score = fit_baseline_model(\n",
    "        train_rf,\n",
    "        data=[(X_train, y_train), (X_validation, y_validation)],\n",
    "        pass_val=False,\n",
    "        params=None,\n",
    "    )\n",
    "\n",
    "    scores_df = get_results(model, data_splits)\n",
    "    # SAVE RESULTS ------\n",
    "    save_model(\n",
    "        model=model, kind=kind, best_score=best_score, scores=scores_df, **saver_params\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433b924e-9efc-4b18-b162-3b48458cd99b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5305496-c1c7-4ee3-8428-aed5ea0528f7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# --- --- --- RF GRID SEARCH --- --- ---\n",
    "if toFitRF:\n",
    "    kind = \"grid\"\n",
    "\n",
    "    search = fit_grid_model(\n",
    "        train_rf,\n",
    "        data=[(X_train, y_train), (X_validation, y_validation)],\n",
    "        grid_params=rf_params,\n",
    "        grid_search_kwargs=grid_search_kwargs,\n",
    "        pass_val=False,\n",
    "        params=None,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    # REFIT TO GET TRAINING ERROR AT EACH STEP ------\n",
    "\n",
    "    model = refit_with_params(\n",
    "        train_rf,\n",
    "        search.best_params_,\n",
    "        data=[(X_train, y_train), (X_validation, y_validation)],\n",
    "        pass_val=False,\n",
    "    )\n",
    "    # Score model ---\n",
    "    scores_df = get_results(model, data_splits)\n",
    "    best_score = search.best_score_\n",
    "    # Save model ---\n",
    "    model_path = save_model(\n",
    "        model=model, kind=kind, best_score=best_score, scores=scores_df, **saver_params\n",
    "    )\n",
    "    # Save grid search results ---\n",
    "    save_grid(model_path=model_path, search=search, **saver_grid_params)\n",
    "    # boost.get_booster().feature_names= important_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de5fa8a-f551-4a9e-bfe3-18270ce751e8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### REFIT on subsample of cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864224a8-aa00-41d0-af17-605eefc1fcf4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if toFitRF:\n",
    "    model, important_cols, subset, best_score = refit_with_selection(\n",
    "        train_rf,\n",
    "        [(X_train, y_train), (X_validation, y_validation)],\n",
    "        model_with_importances=model,\n",
    "        all_cols=all_cols,\n",
    "        grid_params=rf_params,\n",
    "        grid_search_kwargs=grid_search_kwargs,\n",
    "        pass_val=False,\n",
    "        params=None,\n",
    "        best_params=search.best_params_,\n",
    "        th=0.001,\n",
    "        verbose=False,\n",
    "    )\n",
    "    data_splits_th = [\n",
    "        (data_splits[0][0][:, subset], data_splits[0][1]),\n",
    "        (data_splits[1][0][:, subset], data_splits[1][1]),\n",
    "        (data_splits[2][0][:, subset], data_splits[2][1]),\n",
    "    ]\n",
    "\n",
    "    scores_df = get_results(model, data_splits_th)\n",
    "    # Save model ---\n",
    "    kind = \"refit\"\n",
    "    model_path = save_model(\n",
    "        model=model, kind=kind, best_score=best_score, scores=scores_df, **saver_params\n",
    "    )\n",
    "    # Save grid search results ---\n",
    "    # save_grid(model_path=model_path, search=search, **saver_grid_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5064110c-cb60-4d11-bd26-af84038d9aba",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## SVM "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db58ca93-29a5-4e9a-88d0-732c8a9b8d95",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### BASELINE SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7ebe1e-12b5-4dd8-aec0-49a892bcdefb",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "saver_params = dict(\n",
    "    dataset=dataset,\n",
    "    model_name=\"svm\",\n",
    "    objective=\"misclassification\",\n",
    "    toScale=toScale,\n",
    "    init_time=init_time,\n",
    "    columns_used=all_cols,\n",
    "    Preprocess=Preprocess,\n",
    "    preprocessing_path=scaler_name,\n",
    "    categorical=categorical,\n",
    ")\n",
    "\n",
    "# --- --- --- BASELINE RF --- --- ---\n",
    "if toFitSVM:\n",
    "    model, kind, best_score = fit_baseline_model(\n",
    "        train_svr,\n",
    "        data=[(X_train, y_train), (X_validation, y_validation)],\n",
    "        pass_val=False,\n",
    "        params=None,\n",
    "    )\n",
    "\n",
    "    scores_df = get_results(model, data_splits)\n",
    "    # SAVE RESULTS ------\n",
    "    save_model(\n",
    "        model=model, kind=kind, best_score=best_score, scores=scores_df, **saver_params\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720fc626-861a-4983-8799-7a52a503670a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### GRID SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4e53fb-2e8c-43a3-b886-f455cadf3fbe",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# --- --- --- SVM GRID SEARCH --- --- ---\n",
    "if toFitSVM:\n",
    "    kind = \"grid\"\n",
    "\n",
    "    search = fit_grid_model(\n",
    "        train_svr,\n",
    "        data=[(X_train, y_train), (X_validation, y_validation)],\n",
    "        grid_params=svm_params,\n",
    "        grid_search_kwargs=grid_search_kwargs,\n",
    "        pass_val=False,\n",
    "        params=None,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    # REFIT TO GET TRAINING ERROR AT EACH STEP ------\n",
    "\n",
    "    model = search.best_estimator_\n",
    "    # Score model ---\n",
    "    scores_df = get_results(model, data_splits)\n",
    "    best_score = search.best_score_\n",
    "    # Save model ---\n",
    "    model_path = save_model(\n",
    "        model=model, kind=kind, best_score=best_score, scores=scores_df, **saver_params\n",
    "    )\n",
    "    # Save grid search results ---\n",
    "    save_grid(model_path=model_path, search=search, **saver_grid_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53356a01-d3c8-459e-80e7-a2b7c3eec8f2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0159fd90-d2c3-4f60-9c80-c7b8fd667149",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### BASELINE MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7bf43b-5d3a-4624-8b19-f7fd6a459d0f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "grid_search_kwargs = dict(\n",
    "    scoring=\"neg_mean_absolute_error\", n_jobs=cpus_to_use, refit=True, cv=skf, verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ac80fa-5401-4541-a2ba-2870ee955369",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "saver_params = dict(\n",
    "    dataset=dataset,\n",
    "    model_name=\"mlp\",\n",
    "    objective=\"mae\",\n",
    "    toScale=toScale,\n",
    "    init_time=init_time,\n",
    "    columns_used=all_cols,\n",
    "    Preprocess=Preprocess,\n",
    "    preprocessing_path=scaler_name,\n",
    "    categorical=categorical,\n",
    ")\n",
    "\n",
    "# --- --- --- BASELINE MLP --- --- ---\n",
    "if toFitMLP:\n",
    "    model, kind, best_score = fit_baseline_model(\n",
    "        train_mlp,\n",
    "        data=[(X_train, y_train), (X_validation, y_validation)],\n",
    "        pass_val=False,\n",
    "        params=None,\n",
    "    )\n",
    "\n",
    "    scores_df = get_results(model, data_splits)\n",
    "    # SAVE RESULTS ------\n",
    "    save_model(\n",
    "        model=model, kind=kind, best_score=best_score, scores=scores_df, **saver_params\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3a44aa-bbd7-4245-9315-48b81c607cc6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### GRID SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b06762-141c-48f6-abb2-7d89fc1e96ef",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# --- --- --- SVM GRID SEARCH --- --- ---\n",
    "if toFitMLP:\n",
    "    kind = \"grid\"\n",
    "\n",
    "    search = fit_grid_model(\n",
    "        train_mlp,\n",
    "        data=[(X_train, y_train), (X_validation, y_validation)],\n",
    "        grid_params=mlp_params,\n",
    "        grid_search_kwargs=grid_search_kwargs,\n",
    "        pass_val=False,\n",
    "        params=None,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    # REFIT TO GET TRAINING ERROR AT EACH STEP ------\n",
    "    model = search.best_estimator_\n",
    "    # Score model ---\n",
    "    scores_df = get_results(model, data_splits)\n",
    "    best_score = search.best_score_\n",
    "    # Save model ---\n",
    "    model_path = save_model(\n",
    "        model=model, kind=kind, best_score=best_score, scores=scores_df, **saver_params\n",
    "    )\n",
    "    # Save grid search results ---\n",
    "    save_grid(model_path=model_path, search=search, **saver_grid_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee426434-3f7c-4088-81dd-861643127a0b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## END "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f22c09b-4b50-4819-9dad-ffc200e71b7d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PRINT EXECUTION TIME ------\n",
    "e = datetime.now()  # end time\n",
    "delta = e - s  # timedelta\n",
    "# extract ---\n",
    "days = delta.days\n",
    "seconds = delta.seconds\n",
    "# calcultate hours, minutes\n",
    "hours = seconds // 3600\n",
    "minutes = (seconds // 60) % 60\n",
    "print(\"------ EXECUTION TIME ------\")\n",
    "print(\"days:\", days, \"hours:\", hours, \"minutes:\", minutes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 13.509124,
   "end_time": "2022-02-07T09:56:55.347231",
   "environment_variables": {},
   "exception": true,
   "input_path": "trainers/model_trainer.ipynb",
   "output_path": "Jupyter Outputs/model_output_07-02-2022_09:55:57.ipynb",
   "parameters": {
    "categorical": false,
    "dataset": "knnImputed",
    "dependent": "PAT_AGE",
    "training_data_path": "knnImputed_path"
   },
   "start_time": "2022-02-07T09:56:41.838107",
   "version": "2.3.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
