{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2d87c22-4387-4aa1-9ad5-d7c515adefd2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# HOUSE PRICES TRAINER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c329355-4ccf-4ef3-88e1-b85c76e3f51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.6\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eab36b8-9bf8-43de-9fc6-456c74b6a0bd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## DATA AND GLOBAL PARAMETERS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f58c2b-ed1f-4287-a6aa-4d83d0f0b263",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdd4665b-d318-44ad-90e0-d2bb500f9c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIRBARIES ------\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "# Misc\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "# Combinatorics\n",
    "from itertools import product\n",
    "from pickle import dump\n",
    "\n",
    "# Matrices\n",
    "import numpy as np\n",
    "\n",
    "# DF\n",
    "import pandas as pd\n",
    "\n",
    "# Boosting machine\n",
    "import xgboost as xgb\n",
    "from IPython.display import Markdown as md\n",
    "from IPython.display import display as printmd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.metrics import (\n",
    "    make_scorer,\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    "    mean_squared_log_error,\n",
    ")\n",
    "from sklearn.model_selection import GridSearchCV, KFold, train_test_split\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.svm import SVC, SVR\n",
    "\n",
    "# SKLEARN ---\n",
    "# * metrics ---\n",
    "\n",
    "# * Preprocess ---\n",
    "\n",
    "# * Imputation\n",
    "\n",
    "# * CV ---\n",
    "\n",
    "# Regression\n",
    "\n",
    "\n",
    "# utils \n",
    "base_path = \"/home/jovyan/work/CM_ML/TP5/Maturite_dentaire\"  # laptop : /home/jovyan/work/CM_ML/TP3_TP4 other tower: /home/jovyan/work/TP3_TP4\n",
    "os.chdir(base_path)\n",
    "sys.path.append(base_path)\n",
    "from utils.utils import rmsle_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae74c8f9-0436-4bd1-b8b4-9b11b9eb18b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting time and time used for files 08-02-2022_13:51:04\n"
     ]
    }
   ],
   "source": [
    "# START TIME ------\n",
    "s = datetime.now()\n",
    "# time as str\n",
    "init_time = s.strftime(\"%d-%m-%Y_%H:%M:%S\")\n",
    "print(f\"Starting time and time used for files {init_time}\")\n",
    "pd.set_option(\"display.float_format\", lambda x: \"%.5f\" % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cde833b-9037-4544-b051-8f8776264fbd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Helper functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3eb0f29-3e7c-4ca0-b863-532b57157a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FROM DATA TO MODEL DATA -----\n",
    "def preprocess_data_as_model(data, dependent, categorical):\n",
    "    # * Divide X,y ---\n",
    "    data_subset = data.drop(dependent, axis=1)\n",
    "    y = data[dependent].values\n",
    "\n",
    "    # handle categorical variables ---\n",
    "    cols_beginning = data_subset.columns.values\n",
    "\n",
    "    all_cols = cols_beginning\n",
    "    numeric_cols = data_subset.select_dtypes([\"number\"]).columns\n",
    "    numeric_cols_index = np.in1d(all_cols, numeric_cols)\n",
    "\n",
    "    categorical_cols = data_subset.select_dtypes([\"object\"]).columns\n",
    "    categorical_cols_index = np.in1d(all_cols, categorical_cols)\n",
    "\n",
    "    # Transformations ---\n",
    "    transformations = []\n",
    "\n",
    "    if categorical:\n",
    "        pass  # todo\n",
    "    else:\n",
    "        # Training cols ---\n",
    "        data_subset = data_subset.select_dtypes([\"number\"])  # drop categorical\n",
    "        all_cols = cols_beginning[numeric_cols_index]  # only numerical cols ....\n",
    "        numeric_cols_index = (\n",
    "            data_subset.columns.values != None\n",
    "        )  # apply transformation to all columns\n",
    "    return (\n",
    "        data_subset,\n",
    "        y,\n",
    "        all_cols,\n",
    "        numeric_cols,\n",
    "        numeric_cols_index,\n",
    "        categorical_cols,\n",
    "        categorical_cols_index,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a33c6740-4817-4146-b107-44a966451313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL TRAINERS ------\n",
    "def train_mlp(data=None, best_params=None):\n",
    "    # * Init xgb instance ---\n",
    "    mlp = MLPRegressor(max_iter=3000, random_state=123, early_stopping=True)\n",
    "    # * Set best params, normally found by a previous Grid search ---\n",
    "    if best_params:\n",
    "        print(f\"Setting best parameters: {best_params}\")\n",
    "        mlp.set_params(**best_params)\n",
    "    if data:\n",
    "        # * Fit mlp: ((x_train,y_train)) ---\n",
    "        mlp.fit(X=data[0], y=data[1])\n",
    "    return mlp\n",
    "\n",
    "\n",
    "def train_svr(data=None, best_params=None):\n",
    "    # * Init xgb instance ---\n",
    "    svr = SVR()\n",
    "    # * Set best params, normally found by a previous Grid search ---\n",
    "    if best_params:\n",
    "        print(f\"Setting best parameters: {best_params}\")\n",
    "        svr.set_params(**best_params)\n",
    "    if data:\n",
    "        # * Fit svr: ((x_train,y_train)) ---\n",
    "        svr.fit(X=data[0], y=data[1])\n",
    "    return svr\n",
    "\n",
    "\n",
    "def train_rf(data=None, best_params=None):\n",
    "    # * Init xgb instance ---\n",
    "    rf = RandomForestRegressor()\n",
    "\n",
    "    # * Set best params, normally found by a previous Grid search ---\n",
    "    if best_params:\n",
    "        print(f\"Setting best parameters: {best_params}\")\n",
    "        rf.set_params(**best_params)\n",
    "    if data:\n",
    "        # * Fit rf: ((x_train,y_train)) ---\n",
    "        rf.fit(X=data[0], y=data[1])\n",
    "    return rf\n",
    "\n",
    "\n",
    "def train_xgb(params, data=None, best_params=None):\n",
    "    # * Init xgb instance ---\n",
    "    boost = xgb.XGBRegressor(**params)\n",
    "\n",
    "    # * Set best params, normally found by a previous Grid search ---\n",
    "    if best_params:\n",
    "        print(f\"Setting best parameters: {best_params}\")\n",
    "        boost.set_params(**best_params)\n",
    "\n",
    "    # * Fit booster: ((x_train,y_train), (x_test,y_test)) ---\n",
    "    if data:\n",
    "        boost.fit(\n",
    "            X=data[0][0],\n",
    "            y=data[0][1],\n",
    "            eval_set=data,  # Validation set for early stopping (validates on test -- last data tuple)\n",
    "            early_stopping_rounds=10,\n",
    "            verbose=0,\n",
    "            #eval_metric=[\"mae\", \"rmse\", \"rmsle\"],\n",
    "            eval_metric=[\"rmse\",\"rmsle\",\"mae\"]\n",
    "        )\n",
    "    return boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8997e70-1f93-4f22-8b3b-37667252e789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL SAVERS ------\n",
    "def save_model(\n",
    "    model,\n",
    "    model_name,\n",
    "    dataset,\n",
    "    kind,\n",
    "    objective,\n",
    "    toScale,\n",
    "    best_score,\n",
    "    init_time,\n",
    "    columns_used,\n",
    "    Preprocess,\n",
    "    preprocessing_path,\n",
    "    categorical,\n",
    "    scores,\n",
    ") -> str:\n",
    "    print(\"\\n\")\n",
    "    print(\"--- Saving model ---\")\n",
    "    model_path = f\"model_dump/{model_name}_{dataset}_{kind}_{objective}_{toScale}_{np.round(best_score,5)}_{init_time}.pkl\"\n",
    "\n",
    "    dump(\n",
    "        {  # options\n",
    "            \"scaled\": toScale,\n",
    "            \"categorical\": categorical,\n",
    "            # processing and model\n",
    "            \"columns_used\": columns_used,\n",
    "            \"preprocess\": Preprocess,\n",
    "            \"model\": model,\n",
    "            \"preprocessing_path\": preprocessing_path,\n",
    "            # outcome\n",
    "            \"scores\": scores,\n",
    "        },\n",
    "        open(model_path, \"wb\"),\n",
    "    )\n",
    "\n",
    "    print(f\"--- {model_name} model saved to {model_path}---\")\n",
    "    return model_path\n",
    "\n",
    "\n",
    "def save_grid(\n",
    "    model_path,\n",
    "    model_name,\n",
    "    dataset,\n",
    "    init_time,\n",
    "    preprocessing_path,\n",
    "    toScale,\n",
    "    categorical,\n",
    "    search,\n",
    "):\n",
    "\n",
    "    res = pd.DataFrame(search.cv_results_)\n",
    "\n",
    "    # * Save estimator ---\n",
    "    res[\"model_path\"] = model_path\n",
    "\n",
    "    # * Did we scale ?\n",
    "    if preprocessing_path:\n",
    "        res[\"preprocessing_path\"] = preprocessing_path\n",
    "    else:\n",
    "        res[\"preprocessing_path\"] = \"no preprocess\"\n",
    "\n",
    "    res[\"categorical\"] = categorical\n",
    "\n",
    "    # * To csv ---\n",
    "    grid_name = f\"grid_search/Grid_{model_name}_{dataset}_{init_time}.csv\"\n",
    "    res.to_csv(grid_name)\n",
    "    print(f\"--- Grid search results saved to {grid_name}---\")\n",
    "\n",
    "\n",
    "def score_model(model, data):\n",
    "    \"\"\"\n",
    "    data = ((xtrain, ytrain), (x_val, y_val), (x_test, y_test))\n",
    "    \"\"\"\n",
    "    splits = [\"train\", \"val\", \"test\"]\n",
    "    scores = {}\n",
    "    for i, split in enumerate(splits):\n",
    "        metrics = {}\n",
    "        metrics[\"rmsle\"] = rmsle(model, data[i][0], data[i][1])\n",
    "        metrics[\"rmse\"] = mean_squared_error(model.predict(data[i][0]), data[i][1])\n",
    "        metrics[\"mae\"] = mean_absolute_error(model.predict(data[i][0]), data[i][1])\n",
    "        scores[split] = metrics\n",
    "    return scores\n",
    "\n",
    "\n",
    "def scores_to_df(scores, verbose=True):\n",
    "    scores_df = pd.DataFrame(scores)\n",
    "    scores_df[\"difference\"] = scores_df[\"train\"] - scores_df[\"val\"]\n",
    "    if verbose:\n",
    "        print(\"---- BEST SCORES ---\")\n",
    "        print(scores_df)\n",
    "    return scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b4b7ec-a38c-4d21-aa0c-0612e45a5c82",
   "metadata": {
    "tags": []
   },
   "source": [
    "### FITTERS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fd0f2d3-111f-427a-aa53-3331fc52e078",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(model, data):\n",
    "    # PRINT BEST RESULTS ------\n",
    "    scores = score_model(model, data)\n",
    "    scores_df = scores_to_df(scores)\n",
    "\n",
    "    best_params = model.get_params()\n",
    "    printmd(md(f\"Paramètres du modèle: {best_params}\"))\n",
    "    return scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3725046-58c1-4ca2-90c9-1be796b02bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_baseline_model(trainer, data, pass_val=False, params=False, **kwargs):\n",
    "    # --- --- --- BASELINE --- --- ---\n",
    "    kind = \"baseline\"\n",
    "\n",
    "    # * Fit if requested ---\n",
    "    if pass_val and params:\n",
    "        model = trainer(params, data, best_params=None)\n",
    "    else:\n",
    "        model = trainer((data[0][0], data[0][1]), best_params=None)\n",
    "\n",
    "    # Best rmsle ---\n",
    "    best_score = rmsle(estimator=model, X=data[1][0], y_true=data[1][1])\n",
    "\n",
    "    return (model, kind, best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7193dc1-5e9c-4890-a2fb-550048092ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_grid_model(\n",
    "    trainer,\n",
    "    data,\n",
    "    grid_params,\n",
    "    grid_search_kwargs,\n",
    "    pass_val=False,\n",
    "    params=False,\n",
    "    verbose=True,\n",
    "):\n",
    "    # --- --- --- BASELINE --- --- ---\n",
    "    kind = \"grid\"\n",
    "\n",
    "    if params:\n",
    "        # * Init instance ---\n",
    "        model = trainer(params=params)\n",
    "    else:\n",
    "        model = trainer()\n",
    "\n",
    "    # * GridSearchCV ---\n",
    "    search = GridSearchCV(model, param_grid=grid_params, **grid_search_kwargs)\n",
    "\n",
    "    # * Fit if requested ---\n",
    "    if pass_val:\n",
    "        search.fit(\n",
    "            data[0][0],\n",
    "            data[0][1],\n",
    "            eval_set=[data[1]],  # Validation set for early stopping\n",
    "            early_stopping_rounds=15,\n",
    "            verbose=0,\n",
    "        )\n",
    "    else:\n",
    "        search.fit(data[0][0], data[0][1])\n",
    "\n",
    "    # PRINT BEST RESULTS ------\n",
    "    if verbose:\n",
    "        best_score = search.best_score_\n",
    "        printmd(\n",
    "            md(\n",
    "                f\"Le meilleur score obtenu par notre grid search (à savoir, le score est le RMSLE): {best_score}\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "        best_params = search.best_params_\n",
    "        printmd(md(f\"Le meilleurs paramètres: {best_params}\"))\n",
    "\n",
    "    return search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99a13e88-d427-4cd6-b689-3d9eedbcc3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def refit_with_params(trainer, best_params, data, pass_val=False):\n",
    "    # * Fit if requested ---\n",
    "    if pass_val and params:\n",
    "        model = trainer(params, data, best_params=best_params)\n",
    "    else:\n",
    "        model = trainer((data[0][0], data[0][1]), best_params=best_params)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0014db5-9140-43bf-824b-3023a0aa4f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def refit_with_selection(\n",
    "    trainer,\n",
    "    data,\n",
    "    model_with_importances,\n",
    "    all_cols,\n",
    "    grid_params,\n",
    "    grid_search_kwargs,\n",
    "    pass_val,\n",
    "    params,\n",
    "    best_params,\n",
    "    th=0.001,\n",
    "    verbose=False,\n",
    "):\n",
    "    # which features ---\n",
    "    subset = model_with_importances.feature_importances_ > th\n",
    "    important_cols = all_cols[subset].tolist()\n",
    "    \n",
    "    if np.all(subset):\n",
    "        print(\"Keeping all columns. Returning model with importances. Increase TH \")\n",
    "        return model_with_importances, subset, important_cols, None\n",
    "    else :\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"IMPORTANT COLUMNS KEPT FOR RETRAINING {important_cols}\")\n",
    "\n",
    "        data_th = [(data[0][0][:, subset], data[0][1]), (data[1][0][:, subset], data[1][1])]\n",
    "        search = fit_grid_model(\n",
    "            trainer, data_th, grid_params, grid_search_kwargs, pass_val, params, verbose\n",
    "        )\n",
    "\n",
    "        model = refit_with_params(\n",
    "            trainer, search.best_params_, data=data_th, pass_val=pass_val\n",
    "        )\n",
    "\n",
    "        best_score = search.best_score_\n",
    "        return model, subset, important_cols, best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebb1be4-f292-49ad-87e6-6860926cc874",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data Paths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b54d143-6978-426a-bc89-6b54855a3959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- --- --- FOLDERS AND FILES --- --- ---\n",
    "\n",
    "# * Wine dataset paths ---\n",
    "data_path = \"data/ordinalEncoder_imputed_knn/\"\n",
    "knnImputed_path= os.path.join(base_path, data_path, \"knn_imputed.csv\")\n",
    "\n",
    "# init scaler\n",
    "scaler_name = None\n",
    "Preprocess = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "89367d19-0135-47d5-95cc-c3421fc8c756",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# --- --- --- MODEL FITTING PARAMETERS --- --- ---\n",
    "\n",
    "# FIT OR LOAD MODEL ------\n",
    "toFitXGB = True\n",
    "toFitRF = True\n",
    "toFitSVM = True\n",
    "toFitMLP = True\n",
    "\n",
    "# * Fitting options ---\n",
    "toScale = True\n",
    "\n",
    "# *Handle categorical vars\n",
    "categorical = True\n",
    "\n",
    "# DEFAULT STORAGE PARAMETERS ------\n",
    "to_rm_storage = False\n",
    "### DATA PARAMETERS ---\n",
    "training_data_path = None\n",
    "dataset = None\n",
    "dependent = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "00cefecb-fddf-4b82-9f23-48f74a30852f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_path= \"knnImputed_path\"\n",
    "\n",
    "dependent=\"PAT_AGE\"\n",
    "categorical = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08150bd-62a2-4d80-b7ca-a8fc033670ad",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Folders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0fb1da5e-e78e-49b4-817d-baff9ff2516d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.39 ms, sys: 188 µs, total: 1.58 ms\n",
      "Wall time: 763 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# FOLDERS TO STORE ------\n",
    "paths_to_create = [\n",
    "    os.path.join(base_path, \"scale_dump\"),\n",
    "    os.path.join(base_path, \"model_dump\"),\n",
    "    os.path.join(base_path, \"grid_search\"),\n",
    "]\n",
    "\n",
    "# REMOVE PREVIOUS STORAGE IF NEEDED ------\n",
    "if to_rm_storage:\n",
    "    print(\"--- Removing previous saved models, grids and scalers ---\")\n",
    "    for folder in paths_to_create:\n",
    "        shutil.rmtree(folder, ignore_errors=True)\n",
    "\n",
    "# (RE)CREATE STORAGE FOLDERS ------\n",
    "for folder in paths_to_create:\n",
    "    os.makedirs(folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7a80e7-c61c-4a9e-8b64-61e04f23457b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## MODEL PARAMETERS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4888bc90-804c-4e00-b3e8-466dc5deff71",
   "metadata": {
    "tags": []
   },
   "source": [
    "### MODEL PARAMETERS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "265249ef-80a6-4525-9773-1595ddf85459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPUS DETECTED : 8\n",
      "CPUS TO USE : 4\n"
     ]
    }
   ],
   "source": [
    "# Multiprocessing ---\n",
    "cpus = multiprocessing.cpu_count()\n",
    "cpu_ratio = 0.5\n",
    "cpus_to_use = int(cpus * cpu_ratio)\n",
    "print(f\"CPUS DETECTED : {cpus}\")\n",
    "print(f\"CPUS TO USE : {cpus_to_use}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c93f4c-c461-4387-abfb-9062fe687a3b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### CV PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5d36cee3-2623-4300-8b83-9520ff00fb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- --- --- CV PARAMS --- --- ---\n",
    "folds = 3\n",
    "rstate = 123\n",
    "\n",
    "# * K Fold ---\n",
    "skf = KFold(n_splits=folds, shuffle=True, random_state=rstate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "77fa33b4-9378-4a0c-9b00-b5277aa25d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- --- --- XGB HYPER PARAMS --- --- ---\n",
    "# * Grid for xgb ---\n",
    "xgb_params = {\n",
    "    \"min_child_weight\": [1, 5, 10],\n",
    "    \"gamma\": [0.001, 0.02, 0.04, 0.08, 0.1, 0.5],\n",
    "    \"subsample\": [0.6, 0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.6, 0.8, 1.0],\n",
    "    \"max_depth\": [1, 3, 5, 6],\n",
    "    \"lambda\": [0, 0.01, 0.02, 0.5, 1],  # no much pbs of overfting\n",
    "}\n",
    "#objective = \"reg:squaredlogerror\"  # metric RMSLE\n",
    "objective = \"reg:squarederror\"  # RMSLE STUCKED ...\n",
    "metric = \"mae\"\n",
    "rmsle = rmsle_scorer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "41b98e16-0c9a-4fae-9eab-2eb1281c43ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Original Number of combinations : 7562\n",
      "RF Number of correct combinations : 1257\n"
     ]
    }
   ],
   "source": [
    "# --- --- --- RANDOM FOREST HYPER PARAMS --- --- ---\n",
    "max_depth_val = 20\n",
    "max_depth = np.arange(1, max_depth_val, 1)\n",
    "max_leaf_nodes = np.arange(\n",
    "    2, max_depth_val * max_depth_val, 1\n",
    ")  # si on ajoute un max_depth x il faut au plus accepter x*x feuilles...\n",
    "\n",
    "params_combinations = list(product(max_depth, max_leaf_nodes))\n",
    "print(\"RF Original Number of combinations : %s\" % len(params_combinations))\n",
    "\n",
    "# REMOVE ILOGIC COMBINATIONS cf.TP2 ------\n",
    "correct_params = []\n",
    "incorrect_params = []\n",
    "for depth, leaves in params_combinations:\n",
    "    max_feuilles = depth * depth\n",
    "    if leaves > max_feuilles or leaves < np.round(0.5 * max_feuilles):  # critères\n",
    "        incorrect_params.append((depth, leaves))\n",
    "    else:\n",
    "        correct_params.append((depth, leaves))\n",
    "\n",
    "rf_params = []\n",
    "for depth, leaves in correct_params:\n",
    "    grille = {\n",
    "        \"max_depth\": [depth],  # wrap in one list element\n",
    "        \"max_leaf_nodes\": [leaves],\n",
    "    }\n",
    "    rf_params.append(grille)\n",
    "\n",
    "print(\"RF Number of correct combinations : %s\" % len(correct_params))\n",
    "assert len(correct_params)>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ee02bc68-6f18-4bca-8eee-62c2a2debd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- --- --- SVM HYPER PARAMS --- --- ---\n",
    "\n",
    "# possibilities ---\n",
    "Cs = np.linspace(0.5, 40, 7)\n",
    "KERNELS = [\"linear\", \"poly\", \"rbf\", \"sigmoid\"]\n",
    "# grid ---\n",
    "svm_params = {\"C\": Cs, \"kernel\": KERNELS}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bd1466d7-326b-453a-8e2d-54d7e32545ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- --- --- MLP HYPER PARAMS --- --- ---\n",
    "\n",
    "mlp_params = {\n",
    "    \"hidden_layer_sizes\": [(50, 50, 50), (50, 100, 50), (100,)],\n",
    "    \"activation\": [\"tanh\", \"relu\"],\n",
    "    \"solver\": [\"sgd\", \"adam\"],\n",
    "    \"alpha\": [0.0001, 0.05],\n",
    "    \"learning_rate\": [\"constant\", \"adaptive\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc8463b-ca71-45ac-a2e7-3df3ae727757",
   "metadata": {
    "tags": []
   },
   "source": [
    "## IMPORT DATA "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f915346b-977c-433d-8ab2-a5a234fd3555",
   "metadata": {
    "tags": []
   },
   "source": [
    "### House "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9efbacad-e9ef-4dbd-97e9-a357ee536079",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.5 ms, sys: 1 µs, total: 12.5 ms\n",
      "Wall time: 10.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# --- --- --- DATA --- --- ---\n",
    "# * Load data ---\n",
    "data = pd.read_csv(eval(training_data_path), sep=\",\")\n",
    "\n",
    "(\n",
    "    data_subset,\n",
    "    y,\n",
    "    all_cols,\n",
    "    numeric_cols,\n",
    "    numeric_cols_index,\n",
    "    categorical_cols,\n",
    "    categorical_cols_index,\n",
    ") = preprocess_data_as_model(data, dependent, categorical)\n",
    "cols_beginning = data_subset.columns.values\n",
    "\n",
    "# DEFINE TRANSFORMATION BASED ON OPTIONS ------\n",
    "# Transformations ---\n",
    "transformations = []\n",
    "if categorical:\n",
    "    # One hot encoder ---\n",
    "    encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "    transformer = (\"cat_cols\", encoder, categorical_cols_index)  # on cat cols\n",
    "    transformations.append(transformer)\n",
    "\n",
    "else:\n",
    "    # Training cols ---\n",
    "    data_subset = data_subset.select_dtypes([\"number\"])  # drop categorical\n",
    "    all_cols = cols_beginning[numeric_cols_index]  # only numerical cols ....\n",
    "    numeric_cols_index = (\n",
    "        data_subset.columns.values != None\n",
    "    )  # apply transformation to all columns\n",
    "\n",
    "\n",
    "# * Optional Scaling ---\n",
    "if toScale:\n",
    "    # unit variance scaler ---\n",
    "    scaler = StandardScaler()\n",
    "    transformer = (\"num_cols\", scaler, numeric_cols_index)  # on num cols\n",
    "    transformations.append(transformer)\n",
    "\n",
    "# * TRAIN VAL TEST SPLIT ---\n",
    "# train test\n",
    "X_train, XHold_test, y_train, yHold_test = train_test_split(\n",
    "    data_subset.values, y, test_size=0.15, random_state=rstate\n",
    ")\n",
    "# train validation\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(\n",
    "    X_train, y_train, test_size=0.15, random_state=rstate\n",
    ")\n",
    "\n",
    "#\n",
    "\n",
    "if toScale or categorical:\n",
    "    print(\n",
    "        f\"--- Column Transformation. Scaling:{toScale} , OneHotEncoder : {categorical}  ---\"\n",
    "    )\n",
    "    Preprocess = ColumnTransformer(\n",
    "        transformations, n_jobs=cpus_to_use, remainder=\"passthrough\"\n",
    "    )\n",
    "    # fit ---\n",
    "    X_train = Preprocess.fit_transform(X_train)\n",
    "    X_validation = Preprocess.transform(X_validation)\n",
    "    XHold_test = Preprocess.transform(XHold_test)\n",
    "\n",
    "    # get names ---\n",
    "    all_cols = Preprocess.get_feature_names_out()\n",
    "\n",
    "    # dump to reuse\n",
    "    scaler_name = f\"scale_dump/ColumnTransformer_{dataset}_{init_time}.pkl\"\n",
    "    dump(Preprocess, open(scaler_name, \"wb\"))\n",
    "\n",
    "# TRAIN VAL TEST SPLIT ------\n",
    "data_splits = [\n",
    "    (X_train, y_train),\n",
    "    (X_validation, y_validation),\n",
    "    (XHold_test, yHold_test),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "be860d2a-1571-4c8f-b5a9-2bd5e978e33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_kwargs = dict(\n",
    "    scoring=rmsle, n_jobs=cpus_to_use, refit=True, cv=skf, verbose=1\n",
    ")\n",
    "\n",
    "grid_search_kwargs = dict(\n",
    "    scoring=\"neg_mean_absolute_error\", n_jobs=cpus_to_use, refit=True, cv=skf, verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed03a8c9-7c6d-4674-a2bd-4be6f7317e27",
   "metadata": {
    "tags": []
   },
   "source": [
    "## XGBOOST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "0b579833-1c02-4c09-8f70-66ebe64593ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn_genetic import GASearchCV\n",
    "import sklearn_genetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "7a65f1a8-6d69-436b-9b0f-66faed03d374",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn_genetic.space import Categorical, Integer, Continuous\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "6710517b-bc8a-4035-b10b-2a4a53649699",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'min_weight_fraction_leaf': Continuous(0.01, 0.5, distribution='log-uniform'),\n",
    "              'bootstrap': Categorical([True, False]),\n",
    "              'max_depth': Integer(2, 30),\n",
    "              'max_leaf_nodes': Integer(2, 35),\n",
    "              'n_estimators': Integer(100, 300)}\n",
    "# The base classifier to tune\n",
    "clf = RandomForestRegressor()\n",
    "\n",
    "# The main class from sklearn-genetic-opt\n",
    "evolved_estimator = GASearchCV(estimator=clf,\n",
    "                               scoring= \"neg_mean_absolute_error\",\n",
    "                              param_grid=param_grid,\n",
    "                              n_jobs=-1,\n",
    "                              verbose=True,error_score= \"raise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "6dae7231-83f1-4030-935b-bb44bc203137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen\tnevals\tfitness \tfitness_std\tfitness_max\tfitness_min\n",
      "0  \t50    \t-1.74889\t0.479117   \t-1.25754   \t-2.82408   \n",
      "1  \t100   \t-1.35831\t0.0949345  \t-1.25513   \t-1.65826   \n",
      "2  \t100   \t-1.29161\t0.0423288  \t-1.2535    \t-1.4691    \n",
      "3  \t100   \t-1.26419\t0.0162011  \t-1.2535    \t-1.33132   \n",
      "4  \t100   \t-1.25578\t0.00202589 \t-1.2535    \t-1.26652   \n",
      "5  \t100   \t-1.25482\t0.00083284 \t-1.25307   \t-1.25691   \n",
      "6  \t100   \t-1.25404\t0.000716669\t-1.25266   \t-1.25592   \n",
      "7  \t100   \t-1.25392\t0.000748711\t-1.25255   \t-1.2558    \n",
      "8  \t100   \t-1.25374\t0.0007171  \t-1.25258   \t-1.2563    \n",
      "9  \t100   \t-1.25327\t0.000820124\t-1.25171   \t-1.25544   \n",
      "10 \t100   \t-1.25341\t0.00101262 \t-1.2516    \t-1.25567   \n",
      "11 \t100   \t-1.25319\t0.000976922\t-1.25144   \t-1.25645   \n",
      "12 \t100   \t-1.25317\t0.000757405\t-1.25144   \t-1.25531   \n",
      "13 \t100   \t-1.25306\t0.000938564\t-1.25132   \t-1.2553    \n",
      "14 \t100   \t-1.25322\t0.00107834 \t-1.25132   \t-1.25557   \n",
      "15 \t100   \t-1.25295\t0.0010204  \t-1.25132   \t-1.25557   \n",
      "16 \t100   \t-1.25298\t0.00085786 \t-1.25132   \t-1.25529   \n",
      "17 \t100   \t-1.25285\t0.00100325 \t-1.25132   \t-1.25587   \n",
      "18 \t100   \t-1.25299\t0.00117834 \t-1.25132   \t-1.25605   \n",
      "19 \t100   \t-1.25249\t0.00100755 \t-1.25057   \t-1.25496   \n",
      "20 \t100   \t-1.25228\t0.00102694 \t-1.25057   \t-1.25445   \n",
      "21 \t100   \t-1.25202\t0.000921231\t-1.25021   \t-1.25445   \n",
      "22 \t100   \t-1.25207\t0.00113934 \t-1.25034   \t-1.25461   \n",
      "23 \t100   \t-1.25181\t0.00123375 \t-1.24968   \t-1.25532   \n",
      "24 \t100   \t-1.25132\t0.000930699\t-1.24968   \t-1.25413   \n",
      "25 \t100   \t-1.25114\t0.000777457\t-1.24968   \t-1.25307   \n",
      "26 \t100   \t-1.25093\t0.000696776\t-1.24968   \t-1.25283   \n",
      "27 \t100   \t-1.251  \t0.000781305\t-1.24968   \t-1.25317   \n",
      "28 \t100   \t-1.2509 \t0.000747765\t-1.24968   \t-1.25243   \n",
      "29 \t100   \t-1.25096\t0.00089493 \t-1.24968   \t-1.25387   \n",
      "30 \t100   \t-1.25103\t0.000945974\t-1.24968   \t-1.25426   \n",
      "31 \t100   \t-1.25083\t0.000773423\t-1.24969   \t-1.25292   \n",
      "32 \t100   \t-1.2508 \t0.000780148\t-1.24969   \t-1.25238   \n",
      "33 \t100   \t-1.25079\t0.000970026\t-1.24969   \t-1.25391   \n",
      "34 \t100   \t-1.25079\t0.000935901\t-1.24925   \t-1.25391   \n",
      "35 \t100   \t-1.25055\t0.00087631 \t-1.24925   \t-1.2526    \n",
      "36 \t100   \t-1.25064\t0.00101816 \t-1.24925   \t-1.25347   \n",
      "37 \t100   \t-1.25066\t0.000895107\t-1.24925   \t-1.25254   \n",
      "38 \t100   \t-1.25064\t0.000819782\t-1.24925   \t-1.25254   \n",
      "39 \t100   \t-1.25066\t0.000892529\t-1.24881   \t-1.25239   \n",
      "40 \t100   \t-1.25085\t0.000941009\t-1.24881   \t-1.255     \n",
      "41 \t100   \t-1.25099\t0.00086132 \t-1.24939   \t-1.25341   \n",
      "42 \t100   \t-1.25084\t0.000724707\t-1.24939   \t-1.25218   \n",
      "43 \t100   \t-1.25101\t0.000854741\t-1.24939   \t-1.2536    \n",
      "44 \t100   \t-1.2508 \t0.000812865\t-1.24939   \t-1.25286   \n",
      "45 \t100   \t-1.25064\t0.000817298\t-1.24939   \t-1.25281   \n",
      "46 \t100   \t-1.25068\t0.000893272\t-1.24935   \t-1.25267   \n",
      "47 \t100   \t-1.25067\t0.00100794 \t-1.24939   \t-1.25393   \n",
      "48 \t100   \t-1.25066\t0.000930855\t-1.24939   \t-1.2531    \n",
      "49 \t100   \t-1.2508 \t0.000817948\t-1.24939   \t-1.2531    \n",
      "50 \t100   \t-1.25069\t0.000934501\t-1.24939   \t-1.25256   \n",
      "51 \t100   \t-1.25065\t0.00086765 \t-1.24939   \t-1.25255   \n",
      "52 \t100   \t-1.25047\t0.000879628\t-1.24939   \t-1.2522    \n",
      "53 \t100   \t-1.25033\t0.0008789  \t-1.24869   \t-1.25296   \n",
      "54 \t100   \t-1.2507 \t0.0011185  \t-1.24869   \t-1.25311   \n",
      "55 \t100   \t-1.2507 \t0.00106995 \t-1.24869   \t-1.25326   \n",
      "56 \t100   \t-1.25044\t0.000820915\t-1.24869   \t-1.25246   \n",
      "57 \t100   \t-1.25066\t0.00100699 \t-1.24869   \t-1.25299   \n",
      "58 \t100   \t-1.25068\t0.000885122\t-1.24869   \t-1.25282   \n",
      "59 \t100   \t-1.25058\t0.000970287\t-1.24869   \t-1.25282   \n",
      "60 \t100   \t-1.25065\t0.00090986 \t-1.24937   \t-1.25225   \n",
      "61 \t100   \t-1.2507 \t0.000723642\t-1.24937   \t-1.25175   \n",
      "62 \t100   \t-1.25062\t0.000888755\t-1.24907   \t-1.25246   \n",
      "63 \t100   \t-1.25036\t0.000934378\t-1.24907   \t-1.25338   \n",
      "64 \t100   \t-1.25051\t0.000814378\t-1.24907   \t-1.25219   \n",
      "65 \t100   \t-1.25059\t0.00102089 \t-1.24907   \t-1.25409   \n",
      "66 \t100   \t-1.25093\t0.000868929\t-1.24907   \t-1.25264   \n",
      "67 \t100   \t-1.25081\t0.000799677\t-1.24907   \t-1.25278   \n",
      "68 \t100   \t-1.25084\t0.000770814\t-1.24907   \t-1.25253   \n",
      "69 \t100   \t-1.25067\t0.000739919\t-1.24907   \t-1.25236   \n",
      "70 \t100   \t-1.2508 \t0.000939805\t-1.24907   \t-1.25296   \n",
      "71 \t100   \t-1.25075\t0.000981565\t-1.24907   \t-1.25242   \n",
      "72 \t100   \t-1.25073\t0.00103047 \t-1.24907   \t-1.25297   \n",
      "73 \t100   \t-1.25076\t0.00092551 \t-1.24907   \t-1.25224   \n",
      "74 \t100   \t-1.25095\t0.00112915 \t-1.24907   \t-1.25362   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/subprocess.py\", line 73, in <module>\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 188, in _run_module_as_main\n",
      "    import msvcrt\n",
      "ModuleNotFoundError: No module named 'msvcrt'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 188, in _run_module_as_main\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 111, in _get_module_details\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 188, in _run_module_as_main\n",
      "Could not import runpy module\n",
      "    __import__(pkg_name)\n",
      "    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/joblib/__init__.py\", line 113, in <module>\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 111, in _get_module_details\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 19, in <module>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 188, in _run_module_as_main\n",
      "    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 111, in _get_module_details\n",
      "    __import__(pkg_name)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/joblib/__init__.py\", line 113, in <module>\n",
      "    from pkgutil import read_code, get_importer\n",
      "  File \"/opt/conda/lib/python3.9/pkgutil.py\", line 23, in <module>\n",
      "    from .memory import Memory, MemorizedResult, register_store_backend\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/joblib/memory.py\", line 28, in <module>\n",
      "    __import__(pkg_name)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/joblib/__init__.py\", line 113, in <module>\n",
      "    from .memory import Memory, MemorizedResult, register_store_backend\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/joblib/memory.py\", line 16, in <module>\n",
      "    from .func_inspect import get_func_code, get_func_name, filter_args\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/joblib/func_inspect.py\", line 18, in <module>\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 188, in _run_module_as_main\n",
      "    import pydoc\n",
      "  File \"/opt/conda/lib/python3.9/pydoc.py\", line 66, in <module>\n",
      "    from .logger import pformat\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/joblib/logger.py\", line 17, in <module>\n",
      "    from .memory import Memory, MemorizedResult, register_store_backend\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/joblib/memory.py\", line 15, in <module>\n",
      "    import logging\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 28, in <module>\n",
      "    import platform\n",
      "    import pathlib\n",
      "  File \"/opt/conda/lib/python3.9/platform.py\", line 119, in <module>\n",
      "  File \"<frozen importlib._bootstrap>\", line 1007, in _find_and_load\n",
      "    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 111, in _get_module_details\n",
      "    from string import Template\n",
      "  File \"/opt/conda/lib/python3.9/string.py\", line 146, in <module>\n",
      "  File \"<frozen importlib._bootstrap>\", line 986, in _find_and_load_unlocked\n",
      "    import subprocess\n",
      "  File \"/opt/conda/lib/python3.9/subprocess.py\", line 78, in <module>\n",
      "    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 111, in _get_module_details\n",
      "    __import__(pkg_name)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/joblib/__init__.py\", line 113, in <module>\n",
      "    Template.__init_subclass__()\n",
      "  File \"/opt/conda/lib/python3.9/string.py\", line 85, in __init_subclass__\n",
      "    import _posixsubprocess\n",
      "  File \"<frozen importlib._bootstrap>\", line 1004, in _find_and_load\n",
      "    __import__(pkg_name)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/joblib/__init__.py\", line 113, in <module>\n",
      "    cls.pattern = _re.compile(pattern, cls.flags | _re.VERBOSE)\n",
      "  File \"/opt/conda/lib/python3.9/re.py\", line 252, in compile\n",
      "  File \"<frozen importlib._bootstrap>\", line 153, in __init__\n",
      "    from .memory import Memory, MemorizedResult, register_store_backend\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/joblib/memory.py\", line 32, in <module>\n",
      "    ModuleInfo = namedtuple('ModuleInfo', 'module_finder name ispkg')\n",
      "  File \"/opt/conda/lib/python3.9/collections/__init__.py\", line 431, in namedtuple\n",
      "    from ._store_backends import StoreBackendBase, FileSystemStoreBackend\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/joblib/_store_backends.py\", line 15, in <module>\n",
      "    return _compile(pattern, flags)\n",
      "  File \"/opt/conda/lib/python3.9/re.py\", line 304, in _compile\n",
      "    from .backports import concurrency_safe_rename\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/joblib/backports.py\", line 13, in <module>\n",
      "    import numpy as np\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/numpy/__init__.py\", line 145, in <module>\n",
      "    p = sre_compile.compile(pattern, flags)\n",
      "  File \"/opt/conda/lib/python3.9/sre_compile.py\", line 768, in compile\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 188, in _run_module_as_main\n",
      "    from . import core\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/numpy/core/__init__.py\", line 70, in <module>\n",
      "    from .memory import Memory, MemorizedResult, register_store_backend\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/joblib/memory.py\", line 32, in <module>\n",
      "    from . import numerictypes as nt\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/numpy/core/numerictypes.py\", line 107, in <module>\n",
      "    from ._store_backends import StoreBackendBase, FileSystemStoreBackend\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/joblib/_store_backends.py\", line 7, in <module>\n",
      "    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 111, in _get_module_details\n",
      "    import json\n",
      "  File \"/opt/conda/lib/python3.9/json/__init__.py\", line 106, in <module>\n",
      "  File \"<frozen importlib._bootstrap>\", line 680, in _load_unlocked\n",
      "    __import__(pkg_name)\n",
      "    code = _code(p, flags)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/joblib/__init__.py\", line 113, in <module>\n",
      "  File \"/opt/conda/lib/python3.9/sre_compile.py\", line 607, in _code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 846, in exec_module\n",
      "    from .decoder import JSONDecoder, JSONDecodeError\n",
      "  File \"/opt/conda/lib/python3.9/json/decoder.py\", line 5, in <module>\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 978, in get_code\n",
      "    from json import scanner\n",
      "  File \"/opt/conda/lib/python3.9/json/scanner.py\", line 5, in <module>\n",
      "    from .memory import Memory, MemorizedResult, register_store_backend\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/joblib/memory.py\", line 32, in <module>\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 647, in _compile_bytecode\n",
      "KeyboardInterrupt\n",
      "    from ._store_backends import StoreBackendBase, FileSystemStoreBackend\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/joblib/_store_backends.py\", line 15, in <module>\n",
      "    _compile(code, p.data, flags)\n",
      "  File \"/opt/conda/lib/python3.9/sre_compile.py\", line 209, in _compile\n",
      "    from .backports import concurrency_safe_rename\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/joblib/backports.py\", line 13, in <module>\n",
      "    import numpy as np\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/numpy/__init__.py\", line 145, in <module>\n",
      "    _compile(code, av, flags)\n",
      "  File \"/opt/conda/lib/python3.9/sre_compile.py\", line 90, in _compile\n",
      "    from . import core\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/numpy/core/__init__.py\", line 22, in <module>\n",
      "    for op, av in pattern:\n",
      "  File \"/opt/conda/lib/python3.9/sre_parse.py\", line 165, in __getitem__\n",
      "    from . import multiarray\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/numpy/core/multiarray.py\", line 1135, in <module>\n",
      "    if isinstance(index, slice):\n",
      "KeyboardInterrupt\n",
      "    def packbits(a, axis=None, bitorder='big'):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/numpy/core/overrides.py\", line 228, in decorator\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 188, in _run_module_as_main\n",
      "    return array_function_dispatch(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/numpy/core/overrides.py\", line 201, in decorator\n",
      "    source_object = compile(\n",
      "KeyboardInterrupt\n",
      "    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 111, in _get_module_details\n",
      "    __import__(pkg_name)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/joblib/__init__.py\", line 113, in <module>\n",
      "    from .memory import Memory, MemorizedResult, register_store_backend\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/joblib/memory.py\", line 16, in <module>\n",
      "    import pydoc\n",
      "  File \"/opt/conda/lib/python3.9/pydoc.py\", line 66, in <module>\n",
      "    import platform\n",
      "  File \"/opt/conda/lib/python3.9/platform.py\", line 119, in <module>\n",
      "    import subprocess\n",
      "  File \"/opt/conda/lib/python3.9/subprocess.py\", line 62, in <module>\n",
      "    import grp\n",
      "  File \"<frozen importlib._bootstrap>\", line 1007, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 982, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 925, in _find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1414, in find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1386, in _get_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1513, in find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 142, in _path_stat\n",
      "KeyboardInterrupt\n",
      "Fatal Python error: Fatal Python error: init_import_site: Failed to import the site module\n",
      "Python runtime state: initialized\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site.py\", line 73, in <module>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 188, in _run_module_as_main\n",
      "    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 111, in _get_module_details\n",
      "    __import__(pkg_name)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/joblib/__init__.py\", line 113, in <module>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 188, in _run_module_as_main\n",
      "    from .memory import Memory, MemorizedResult, register_store_backend\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/joblib/memory.py\", line 28, in <module>\n",
      "    from .func_inspect import get_func_code, get_func_name, filter_args\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/joblib/func_inspect.py\", line 18, in <module>\n",
      "    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 111, in _get_module_details\n",
      "    from .logger import pformat\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/joblib/logger.py\", line 16, in <module>\n",
      "    __import__(pkg_name)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/joblib/__init__.py\", line 113, in <module>\n",
      "    import shutil\n",
      "  File \"<frozen importlib._bootstrap>\", line 1007, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 986, in _find_and_load_unlocked\n",
      "    from .memory import Memory, MemorizedResult, register_store_backend\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/joblib/memory.py\", line 16, in <module>\n",
      "  File \"<frozen importlib._bootstrap>\", line 680, in _load_unlocked\n",
      "    import pydoc\n",
      "  File \"/opt/conda/lib/python3.9/pydoc.py\", line 62, in <module>\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 846, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 978, in get_code\n",
      "    import inspect\n",
      "  File \"/opt/conda/lib/python3.9/inspect.py\", line 35, in <module>\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 647, in _compile_bytecode\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 188, in _run_module_as_main\n",
      "    import ast\n",
      "  File \"<frozen importlib._bootstrap>\", line 1007, in _find_and_load\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 188, in _run_module_as_main\n",
      "  File \"<frozen importlib._bootstrap>\", line 986, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 680, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 846, in exec_module\n",
      "init_import_site    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n",
      ": Failed to import the site module\n",
      "Python runtime state:   File \"/opt/conda/lib/python3.9/runpy.py\", line 111, in _get_module_details\n",
      "initialized\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 978, in get_code\n",
      "    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 111, in _get_module_details\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site.py\", line 589, in <module>\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 647, in _compile_bytecode\n",
      "    __import__(pkg_name)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/joblib/__init__.py\", line 113, in <module>\n",
      "KeyboardInterrupt\n",
      "    from .memory import Memory, MemorizedResult, register_store_backend\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/joblib/memory.py\", line 27, in <module>\n",
      "    from . import hashing\n",
      "  File \"<frozen importlib._bootstrap>\", line 1007, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 986, in _find_and_load_unlocked\n",
      "    import os\n",
      "  File \"/opt/conda/lib/python3.9/os.py\", line 61, in <module>\n",
      "  File \"<frozen importlib._bootstrap>\", line 666, in _load_unlocked\n",
      "    main()\n",
      "  File \"/opt/conda/lib/python3.9/site.py\", line 576, in main\n",
      "  File \"<frozen importlib._bootstrap>\", line 571, in module_from_spec\n",
      "  File \"<frozen importlib._bootstrap>\", line 550, in _init_module_attrs\n",
      "  File \"<frozen importlib._bootstrap>\", line 391, in cached\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 492, in _get_cached\n",
      "KeyboardInterrupt\n",
      "    known_paths = addsitepackages(known_paths)\n",
      "  File \"/opt/conda/lib/python3.9/site.py\", line 359, in addsitepackages\n",
      "    addsitedir(sitedir, known_paths)\n",
      "  File \"/opt/conda/lib/python3.9/site.py\", line 208, in addsitedir\n",
      "    __import__(pkg_name)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/joblib/__init__.py\", line 113, in <module>\n",
      "    addpackage(sitedir, name, known_paths)\n",
      "  File \"/opt/conda/lib/python3.9/site.py\", line 169, in addpackage\n",
      "    exec(line)\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/conda/lib/python3.9/importlib/util.py\", line 2, in <module>\n",
      "    from . import abc\n",
      "  File \"/opt/conda/lib/python3.9/importlib/abc.py\", line 17, in <module>\n",
      "    from typing import Protocol, runtime_checkable\n",
      "  File \"/opt/conda/lib/python3.9/typing.py\", line 26, in <module>\n",
      "    import posixpath as path\n",
      "  File \"/opt/conda/lib/python3.9/posixpath.py\", line 28, in <module>\n",
      "    import re as stdlib_re  # Avoid confusion with the re we export.\n",
      "  File \"/opt/conda/lib/python3.9/re.py\", line 124, in <module>\n",
      "    import enum\n",
      "  File \"<frozen importlib._bootstrap>\", line 1007, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 982, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 925, in _find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1414, in find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1386, in _get_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1547, in find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1501, in _get_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1006, in __init__\n",
      "KeyboardInterrupt\n",
      "    from .memory import Memory, MemorizedResult, register_store_backend\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/joblib/memory.py\", line 16, in <module>\n",
      "    import pydoc\n",
      "  File \"/opt/conda/lib/python3.9/pydoc.py\", line 62, in <module>\n",
      "    import inspect\n",
      "  File \"/opt/conda/lib/python3.9/inspect.py\", line 41, in <module>\n",
      "    import linecache\n",
      "  File \"/opt/conda/lib/python3.9/linecache.py\", line 11, in <module>\n",
      "    import tokenize\n",
      "  File \"<frozen importlib._bootstrap>\", line 1007, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 986, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 680, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 846, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 978, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 647, in _compile_bytecode\n",
      "KeyboardInterrupt\n",
      "    import genericpath\n",
      "  File \"<frozen importlib._bootstrap>\", line 1007, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 982, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 925, in _find_spec\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1847/3790622407.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train and optimize the estimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mevolved_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn_genetic/genetic_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, callbacks)\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_iterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_gen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m         self.cv_results_ = create_gasearch_cv_results_(\n\u001b[0m\u001b[1;32m    526\u001b[0m             \u001b[0mlogbook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogbook\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn_genetic/utils/cv_scores.py\u001b[0m in \u001b[0;36mcreate_gasearch_cv_results_\u001b[0;34m(logbook, space, return_train_score, metrics)\u001b[0m\n\u001b[1;32m     25\u001b[0m             ]\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         cv_results[f\"mean_test_{metric}\"] = [\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcv_scores\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlogbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchapters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"parameters\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"test_{metric}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn_genetic/utils/cv_scores.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         cv_results[f\"mean_test_{metric}\"] = [\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcv_scores\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlogbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchapters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"parameters\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"test_{metric}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         ]\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mnanmean\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/numpy/lib/nanfunctions.py\u001b[0m in \u001b[0;36mnanmean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m     \u001b[0misbad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcnt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 953\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0misbad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    954\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mean of empty slice\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRuntimeWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m         \u001b[0;31m# NaN is the only possible bad value, so no further\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_any\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;31m# Parsing keyword arguments is currently fairly slow, so avoid it for now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwhere\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mumr_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    " # Train and optimize the estimator\n",
    "evolved_estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "440df297-4544-451f-ac2b-1ee51e43bf79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn_genetic.space.space.Categorical at 0x7f9ec9ef27c0>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Categorical(choices= [\"linear\",\"poly\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b31cdf5c-e1e8-4709-98c5-7d96bd7f8a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "saver_params = dict(\n",
    "    dataset=dataset,\n",
    "    model_name=\"xgb\",\n",
    "    objective=objective,\n",
    "    toScale=toScale,\n",
    "    init_time=init_time,\n",
    "    columns_used=all_cols,\n",
    "    Preprocess=Preprocess,\n",
    "    preprocessing_path=scaler_name,\n",
    "    categorical=categorical,\n",
    ")\n",
    "\n",
    "saver_grid_params = {}\n",
    "for i in [\n",
    "    \"model_name\",\n",
    "    \"dataset\",\n",
    "    \"init_time\",\n",
    "    \"preprocessing_path\",\n",
    "    \"toScale\",\n",
    "    \"categorical\",\n",
    "]:\n",
    "    saver_grid_params[i] = saver_params.get(i)\n",
    "\n",
    "params = {\n",
    "    \"objective\": objective,\n",
    "    \"learning_rate\": 0.02,\n",
    "    \"n_estimators\": 700,\n",
    "    \"n_jobs\": 1,  # if not defaults to -1...\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4faa5f84-83b9-4c90-892c-f10422123b66",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### BASIC MODEL (NO HPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "501cb85c-62ca-4c35-a8f1-a931c38caa35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- BEST SCORES ---\n",
      "               train             val       difference\n",
      "rmsle       -0.00141        -0.01715          0.01574\n",
      "rmse  26962071.28822 680274108.03494 -653312036.74672\n",
      "mae       3835.20401     16359.16402     -12523.96001\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Paramètres du modèle: {'objective': 'reg:squarederror', 'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 1, 'enable_categorical': False, 'gamma': 0, 'gpu_id': -1, 'importance_type': None, 'interaction_constraints': '', 'learning_rate': 0.02, 'max_delta_step': 0, 'max_depth': 6, 'min_child_weight': 1, 'missing': nan, 'monotone_constraints': '()', 'n_estimators': 700, 'n_jobs': 1, 'num_parallel_tree': 1, 'predictor': 'auto', 'random_state': 0, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'subsample': 1, 'tree_method': 'exact', 'validate_parameters': 1, 'verbosity': None}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- Saving model ---\n",
      "--- xgb model saved to model_dump/xgb_house_baseline_reg:squarederror_True_-0.01715_04-02-2022_20:19:07.pkl---\n",
      "CPU times: user 9.9 s, sys: 7.99 ms, total: 9.9 s\n",
      "Wall time: 9.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# --- --- --- XGBOOST --- --- ---\n",
    "if toFitXGB:\n",
    "    model, kind, best_score = fit_baseline_model(\n",
    "        train_xgb,\n",
    "        data=[(X_train, y_train), (X_validation, y_validation)],\n",
    "        pass_val=True,\n",
    "        params=params,\n",
    "    )\n",
    "\n",
    "    scores_df = get_results(model, data_splits)\n",
    "    # SAVE RESULTS ------\n",
    "    save_model(\n",
    "        model=model, kind=kind, best_score=best_score, scores=scores_df, **saver_params\n",
    "    )\n",
    "    # boost.get_booster().feature_names= important_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729e4e95-b6e4-4fd5-89e0-f7d05ca2450f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### GRID SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "37755148-2fa9-464f-a20d-6c209325bef5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Le meilleur score obtenu par notre grid search (à savoir, le score est le RMSLE): -0.020333612485709807"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Le meilleurs paramètres: {'min_child_weight': 5}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting best parameters: {'objective': 'reg:squarederror', 'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 1, 'gamma': 0, 'gpu_id': -1, 'interaction_constraints': '', 'learning_rate': 0.02, 'max_delta_step': 0, 'max_depth': 6, 'min_child_weight': 5, 'monotone_constraints': '()', 'n_jobs': 1, 'num_parallel_tree': 1, 'predictor': 'auto', 'random_state': 0, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'subsample': 1, 'tree_method': 'exact', 'validate_parameters': 1, 'verbosity': None}\n",
      "---- BEST SCORES ---\n",
      "               train             val       difference\n",
      "rmsle       -0.00220        -0.01664          0.01444\n",
      "rmse  45670448.67491 682049727.05744 -636379278.38254\n",
      "mae       4948.55395     15708.35536     -10759.80142\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Paramètres du modèle: {'objective': 'reg:squarederror', 'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 1, 'enable_categorical': False, 'gamma': 0, 'gpu_id': -1, 'importance_type': None, 'interaction_constraints': '', 'learning_rate': 0.02, 'max_delta_step': 0, 'max_depth': 6, 'min_child_weight': 5, 'missing': nan, 'monotone_constraints': '()', 'n_estimators': 700, 'n_jobs': 1, 'num_parallel_tree': 1, 'predictor': 'auto', 'random_state': 0, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'subsample': 1, 'tree_method': 'exact', 'validate_parameters': 1, 'verbosity': None}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- Saving model ---\n",
      "--- xgb model saved to model_dump/xgb_house_grid_reg:squarederror_True_-0.01715_04-02-2022_20:19:07.pkl---\n",
      "--- Grid search results saved to grid_search/Grid_xgb_house_04-02-2022_20:19:07.csv---\n",
      "CPU times: user 24.4 s, sys: 16 ms, total: 24.4 s\n",
      "Wall time: 49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# --- --- --- XGBOOST GRID SEARCH --- --- ---\n",
    "if toFitXGB:\n",
    "    kind = \"grid\"\n",
    "\n",
    "    search = fit_grid_model(\n",
    "        train_xgb,\n",
    "        data=[(X_train, y_train), (X_validation, y_validation)],\n",
    "        grid_params=xgb_params,\n",
    "        grid_search_kwargs=grid_search_kwargs,\n",
    "        pass_val=True,\n",
    "        params=params,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    # REFIT TO GET TRAINING ERROR AT EACH STEP ------\n",
    "\n",
    "    model = refit_with_params(\n",
    "        train_xgb,\n",
    "        search.best_estimator_.get_xgb_params(),\n",
    "        data=[(X_train, y_train), (X_validation, y_validation)],\n",
    "        pass_val=True,\n",
    "    )\n",
    "    # Score model ---\n",
    "    scores_df = get_results(model, data_splits)\n",
    "    best_score = search.best_score_\n",
    "    # Save model ---\n",
    "    model_path = save_model(\n",
    "        model=model, kind=kind, best_score=best_score, scores=scores_df, **saver_params\n",
    "    )\n",
    "    # Save grid search results ---\n",
    "    save_grid(model_path=model_path, search=search, **saver_grid_params)\n",
    "    # boost.get_booster().feature_names= important_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c0b82c-7cb2-4898-baab-f916b1766e6d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Refit on feature selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c9486b96-a180-47ca-8e50-54bfae922f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "Setting best parameters: {'objective': 'reg:squarederror', 'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 1, 'gamma': 0, 'gpu_id': -1, 'interaction_constraints': '', 'learning_rate': 0.02, 'max_delta_step': 0, 'max_depth': 6, 'min_child_weight': 5, 'monotone_constraints': '()', 'n_jobs': 1, 'num_parallel_tree': 1, 'predictor': 'auto', 'random_state': 0, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'subsample': 1, 'tree_method': 'exact', 'validate_parameters': 1, 'verbosity': None}\n",
      "---- BEST SCORES ---\n",
      "               train             val       difference\n",
      "rmsle       -0.00220        -0.01664          0.01444\n",
      "rmse  45670448.67491 682049727.05744 -636379278.38254\n",
      "mae       4948.55395     15708.35536     -10759.80142\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Paramètres du modèle: {'objective': 'reg:squarederror', 'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 1, 'enable_categorical': False, 'gamma': 0, 'gpu_id': -1, 'importance_type': None, 'interaction_constraints': '', 'learning_rate': 0.02, 'max_delta_step': 0, 'max_depth': 6, 'min_child_weight': 5, 'missing': nan, 'monotone_constraints': '()', 'n_estimators': 700, 'n_jobs': 1, 'num_parallel_tree': 1, 'predictor': 'auto', 'random_state': 0, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'subsample': 1, 'tree_method': 'exact', 'validate_parameters': 1, 'verbosity': None}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- Saving model ---\n",
      "--- xgb model saved to model_dump/xgb_house_grid_reg:squarederror_True_-0.01715_04-02-2022_20:19:07.pkl---\n",
      "--- Grid search results saved to grid_search/Grid_xgb_house_04-02-2022_20:19:07.csv---\n"
     ]
    }
   ],
   "source": [
    "if toFitXGB:\n",
    "    model, subset,important_cols, best_score = refit_with_selection(\n",
    "        train_xgb,\n",
    "        [(X_train, y_train), (X_validation, y_validation)],\n",
    "        model_with_importances=model,\n",
    "        all_cols=all_cols,\n",
    "        grid_params=xgb_params,\n",
    "        grid_search_kwargs=grid_search_kwargs,\n",
    "        pass_val=True,\n",
    "        params=params,\n",
    "        best_params=search.best_estimator_.get_xgb_params(),\n",
    "        th=0.01,\n",
    "        verbose=False,\n",
    "    )\n",
    "    if not best_score: \n",
    "        best_score = search.best_score_\n",
    "\n",
    "    model.get_booster().feature_names = important_cols\n",
    "\n",
    "    data_splits_th = [\n",
    "        (data_splits[0][0][:, subset], data_splits[0][1]),\n",
    "        (data_splits[1][0][:, subset], data_splits[1][1]),\n",
    "        (data_splits[2][0][:, subset], data_splits[2][1]),\n",
    "    ]\n",
    "\n",
    "    scores_df = get_results(model, data_splits_th)\n",
    "    # Save model ---\n",
    "    kind = \"refit\"\n",
    "    saver_params[\"columns_used\"] = subset\n",
    "    model_path = save_model(\n",
    "        model=model, kind=kind, best_score=best_score, scores=scores_df, **saver_params\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92dc3d7-6238-447e-81e5-44d0863987f7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## RF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3c4c47ec-7d1d-40be-ba9d-00db2bf58dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Column Transformation. Scaling:True , OneHotEncoder : True, Imputer : knnImputer  ---\n"
     ]
    }
   ],
   "source": [
    "# * Split for learning ---\n",
    "# train test\n",
    "if toFitRF or toFitMLP or toFitSVM:\n",
    "\n",
    "    X_train, XHold_test, y_train, yHold_test = train_test_split(\n",
    "        data_subset.values, y, test_size=0.15, random_state=rstate\n",
    "    )\n",
    "    # train validation\n",
    "    X_train, X_validation, y_train, y_validation = train_test_split(\n",
    "        X_train, y_train, test_size=0.15, random_state=rstate\n",
    "    )\n",
    "\n",
    "    knnI = KNNImputer()\n",
    "    #\n",
    "    if toScale or categorical:\n",
    "        print(\n",
    "            f\"--- Column Transformation. Scaling:{toScale} , OneHotEncoder : {categorical}, Imputer : knnImputer  ---\"\n",
    "        )\n",
    "        Preprocess = ColumnTransformer(\n",
    "            transformations, n_jobs=cpus_to_use, remainder=\"passthrough\"\n",
    "        )\n",
    "\n",
    "        Preprocess = Pipeline([(\"col_trans\", Preprocess), (\"imputer\", knnI)])\n",
    "    else:\n",
    "        Preprocess = Pipeline([(\"imputer\", knnI)])\n",
    "\n",
    "    # fit ---\n",
    "    Preprocess.fit(X_train)\n",
    "    X_train = Preprocess.transform(X_train)\n",
    "    X_validation = Preprocess.transform(X_validation)\n",
    "    XHold_test = Preprocess.transform(XHold_test)\n",
    "\n",
    "    # get names ---\n",
    "    if toScale or categorical:\n",
    "\n",
    "        all_cols = Preprocess[0].get_feature_names_out()\n",
    "\n",
    "    # dump to reuse\n",
    "    preprocessing_name = f\"scale_dump/ColumnTransformer__rf_{init_time}.pkl\"\n",
    "    dump(Preprocess, open(preprocessing_name, \"wb\"))\n",
    "\n",
    "# TRAIN VAL TEST SPLIT ------\n",
    "data_splits = [\n",
    "    (X_train, y_train),\n",
    "    (X_validation, y_validation),\n",
    "    (XHold_test, yHold_test),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a48298-3ca5-4168-bc0a-d9fceda01119",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### BASIC MODEL (NO HPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6fa7e26e-bda0-4988-b044-ff6a03618153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- BEST SCORES ---\n",
      "                train             val       difference\n",
      "rmsle        -0.00407        -0.02054          0.01647\n",
      "rmse  154311489.74082 808284019.05005 -653972529.30922\n",
      "mae        6774.71075     18429.64540     -11654.93465\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Paramètres du modèle: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- Saving model ---\n",
      "--- rf model saved to model_dump/rf_house_baseline_squared_error_True_-0.02054_04-02-2022_20:19:07.pkl---\n",
      "CPU times: user 2.1 s, sys: 12 ms, total: 2.11 s\n",
      "Wall time: 2.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "saver_params = dict(\n",
    "    dataset=dataset,\n",
    "    model_name=\"rf\",\n",
    "    objective=\"squared_error\",\n",
    "    toScale=toScale,\n",
    "    init_time=init_time,\n",
    "    columns_used=all_cols,\n",
    "    Preprocess=Preprocess,\n",
    "    preprocessing_path=scaler_name,\n",
    "    categorical=categorical,\n",
    ")\n",
    "# --- --- --- BASELINE RF --- --- ---\n",
    "if toFitRF:\n",
    "    model, kind, best_score = fit_baseline_model(\n",
    "        train_rf,\n",
    "        data=[(X_train, y_train), (X_validation, y_validation)],\n",
    "        pass_val=False,\n",
    "        params=None,\n",
    "    )\n",
    "\n",
    "    scores_df = get_results(model, data_splits)\n",
    "    # SAVE RESULTS ------\n",
    "    save_model(\n",
    "        model=model, kind=kind, best_score=best_score, scores=scores_df, **saver_params\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433b924e-9efc-4b18-b162-3b48458cd99b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5305496-c1c7-4ee3-8428-aed5ea0528f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 912 candidates, totalling 2736 fits\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# --- --- --- RF GRID SEARCH --- --- ---\n",
    "if toFitRF:\n",
    "    kind = \"grid\"\n",
    "\n",
    "    search = fit_grid_model(\n",
    "        train_rf,\n",
    "        data=[(X_train, y_train), (X_validation, y_validation)],\n",
    "        grid_params=rf_params,\n",
    "        grid_search_kwargs=grid_search_kwargs,\n",
    "        pass_val=False,\n",
    "        params=None,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    # REFIT TO GET TRAINING ERROR AT EACH STEP ------\n",
    "\n",
    "    model = refit_with_params(\n",
    "        train_rf,\n",
    "        search.best_params_,\n",
    "        data=[(X_train, y_train), (X_validation, y_validation)],\n",
    "        pass_val=False,\n",
    "    )\n",
    "    # Score model ---\n",
    "    scores_df = get_results(model, data_splits)\n",
    "    best_score = search.best_score_\n",
    "    # Save model ---\n",
    "    model_path = save_model(\n",
    "        model=model, kind=kind, best_score=best_score, scores=scores_df, **saver_params\n",
    "    )\n",
    "    # Save grid search results ---\n",
    "    save_grid(model_path=model_path, search=search, **saver_grid_params)\n",
    "    # boost.get_booster().feature_names= important_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de5fa8a-f551-4a9e-bfe3-18270ce751e8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### REFIT on subsample of cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864224a8-aa00-41d0-af17-605eefc1fcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if toFitRF:\n",
    "    model, subset,important_cols, best_score = refit_with_selection(\n",
    "        train_rf,\n",
    "        [(X_train, y_train), (X_validation, y_validation)],\n",
    "        model_with_importances=model,\n",
    "        all_cols=all_cols,\n",
    "        grid_params=rf_params,\n",
    "        grid_search_kwargs=grid_search_kwargs,\n",
    "        pass_val=False,\n",
    "        params=None,\n",
    "        best_params=search.best_params_,\n",
    "        th=0.01,\n",
    "        verbose=False,\n",
    "    )\n",
    "    \n",
    "    if not best_score: \n",
    "        best_score = search.best_score_\n",
    "        \n",
    "    data_splits_th = [\n",
    "        (data_splits[0][0][:, subset], data_splits[0][1]),\n",
    "        (data_splits[1][0][:, subset], data_splits[1][1]),\n",
    "        (data_splits[2][0][:, subset], data_splits[2][1]),\n",
    "    ]\n",
    "\n",
    "    scores_df = get_results(model, data_splits_th)\n",
    "    # Save model ---\n",
    "    kind = \"refit\"\n",
    "    saver_params[\"columns_used\"] = subset\n",
    "    model_path = save_model(\n",
    "        model=model, kind=kind, best_score=best_score, scores=scores_df, **saver_params\n",
    "    )\n",
    "    # Save grid search results ---\n",
    "    # save_grid(model_path=model_path, search=search, **saver_grid_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5064110c-cb60-4d11-bd26-af84038d9aba",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## SVM "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db58ca93-29a5-4e9a-88d0-732c8a9b8d95",
   "metadata": {
    "tags": []
   },
   "source": [
    "### BASELINE SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d7ebe1e-12b5-4dd8-aec0-49a892bcdefb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
      "Wall time: 4.77 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "saver_params = dict(\n",
    "    dataset=dataset,\n",
    "    model_name=\"svm\",\n",
    "    objective=\"misclassification\",\n",
    "    toScale=toScale,\n",
    "    init_time=init_time,\n",
    "    columns_used=all_cols,\n",
    "    Preprocess=Preprocess,\n",
    "    preprocessing_path=scaler_name,\n",
    "    categorical=categorical,\n",
    ")\n",
    "\n",
    "# --- --- --- BASELINE RF --- --- ---\n",
    "if toFitSVM:\n",
    "    model, kind, best_score = fit_baseline_model(\n",
    "        train_svr,\n",
    "        data=[(X_train, y_train), (X_validation, y_validation)],\n",
    "        pass_val=False,\n",
    "        params=None,\n",
    "    )\n",
    "\n",
    "    scores_df = get_results(model, data_splits)\n",
    "    # SAVE RESULTS ------\n",
    "    save_model(\n",
    "        model=model, kind=kind, best_score=best_score, scores=scores_df, **saver_params\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720fc626-861a-4983-8799-7a52a503670a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### GRID SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d4e53fb-2e8c-43a3-b886-f455cadf3fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 4.77 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# --- --- --- SVM GRID SEARCH --- --- ---\n",
    "if toFitSVM:\n",
    "    kind = \"grid\"\n",
    "\n",
    "    search = fit_grid_model(\n",
    "        train_svr,\n",
    "        data=[(X_train, y_train), (X_validation, y_validation)],\n",
    "        grid_params=svm_params,\n",
    "        grid_search_kwargs=grid_search_kwargs,\n",
    "        pass_val=False,\n",
    "        params=None,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    # REFIT TO GET TRAINING ERROR AT EACH STEP ------\n",
    "\n",
    "    model = search.best_estimator_\n",
    "    # Score model ---\n",
    "    scores_df = get_results(model, data_splits)\n",
    "    best_score = search.best_score_\n",
    "    # Save model ---\n",
    "    model_path = save_model(\n",
    "        model=model, kind=kind, best_score=best_score, scores=scores_df, **saver_params\n",
    "    )\n",
    "    # Save grid search results ---\n",
    "    save_grid(model_path=model_path, search=search, **saver_grid_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53356a01-d3c8-459e-80e7-a2b7c3eec8f2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0159fd90-d2c3-4f60-9c80-c7b8fd667149",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### BASELINE MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7bf43b-5d3a-4624-8b19-f7fd6a459d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_kwargs = dict(\n",
    "    scoring=\"neg_mean_absolute_error\", n_jobs=cpus_to_use, refit=True, cv=skf, verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "19ac80fa-5401-4541-a2ba-2870ee955369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7 µs, sys: 0 ns, total: 7 µs\n",
      "Wall time: 12.4 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "saver_params = dict(\n",
    "    dataset=dataset,\n",
    "    model_name=\"mlp\",\n",
    "    objective=\"mae\",\n",
    "    toScale=toScale,\n",
    "    init_time=init_time,\n",
    "    columns_used=all_cols,\n",
    "    Preprocess=Preprocess,\n",
    "    preprocessing_path=scaler_name,\n",
    "    categorical=categorical,\n",
    ")\n",
    "\n",
    "# --- --- --- BASELINE MLP --- --- ---\n",
    "if toFitMLP:\n",
    "    model, kind, best_score = fit_baseline_model(\n",
    "        train_mlp,\n",
    "        data=[(X_train, y_train), (X_validation, y_validation)],\n",
    "        pass_val=False,\n",
    "        params=None,\n",
    "    )\n",
    "\n",
    "    scores_df = get_results(model, data_splits)\n",
    "    # SAVE RESULTS ------\n",
    "    save_model(\n",
    "        model=model, kind=kind, best_score=best_score, scores=scores_df, **saver_params\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3a44aa-bbd7-4245-9315-48b81c607cc6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### GRID SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e9b06762-141c-48f6-abb2-7d89fc1e96ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
      "Wall time: 6.44 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# --- --- --- SVM GRID SEARCH --- --- ---\n",
    "if toFitMLP:\n",
    "    kind = \"grid\"\n",
    "\n",
    "    search = fit_grid_model(\n",
    "        train_mlp,\n",
    "        data=[(X_train, y_train), (X_validation, y_validation)],\n",
    "        grid_params=mlp_params,\n",
    "        grid_search_kwargs=grid_search_kwargs,\n",
    "        pass_val=False,\n",
    "        params=None,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    # REFIT TO GET TRAINING ERROR AT EACH STEP ------\n",
    "    model = search.best_estimator_\n",
    "    # Score model ---\n",
    "    scores_df = get_results(model, data_splits)\n",
    "    best_score = search.best_score_\n",
    "    # Save model ---\n",
    "    model_path = save_model(\n",
    "        model=model, kind=kind, best_score=best_score, scores=scores_df, **saver_params\n",
    "    )\n",
    "    # Save grid search results ---\n",
    "    save_grid(model_path=model_path, search=search, **saver_grid_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee426434-3f7c-4088-81dd-861643127a0b",
   "metadata": {},
   "source": [
    "## END "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0f22c09b-4b50-4819-9dad-ffc200e71b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ EXECUTION TIME ------\n",
      "days: 0 hours: 0 minutes: 1\n"
     ]
    }
   ],
   "source": [
    "# PRINT EXECUTION TIME ------\n",
    "e = datetime.now()  # end time\n",
    "delta = e - s  # timedelta\n",
    "# extract ---\n",
    "days = delta.days\n",
    "seconds = delta.seconds\n",
    "# calcultate hours, minutes\n",
    "hours = seconds // 3600\n",
    "minutes = (seconds // 60) % 60\n",
    "print(\"------ EXECUTION TIME ------\")\n",
    "print(\"days:\", days, \"hours:\", hours, \"minutes:\", minutes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genetic",
   "language": "python",
   "name": "genetic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
